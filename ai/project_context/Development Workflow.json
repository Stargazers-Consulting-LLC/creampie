{
  "ai_metadata": {
    "purpose": "",
    "last_updated": "",
    "template_version": "2.1",
    "ai_tool_compatibility": "",
    "ai_processing_level": "High",
    "required_context": "Git, CI/CD, testing, deployment, project management",
    "validation_required": "Yes",
    "code_generation": "Supported",
    "cross_references": [
      "../guide_docs/Core%20Principles.json",
      "../guide_docs/Language-Specific/Python%20Testing%20Guide.json",
      "../guide_docs/Domain-Specific/Database%20Management%20Guide.json",
      "Architecture%20Overview.json",
      "Common%20Patterns.json"
    ],
    "maintenance": ""
  },
  "file_info": {
    "file_path": "project_context/Development Workflow.md",
    "original_format": "markdown",
    "converted_at": "2025-06-18T19:14:30.264533",
    "file_size": 18358,
    "line_count": 671,
    "optimized_at": "2025-06-18T19:19:47.760636",
    "optimization_version": "1.0"
  },
  "content": {
    "sections": [
      {
        "level": 1,
        "title": "Development Workflow",
        "content": "> This document describes the development workflow and processes used in the project. Use this for understanding how development tasks are organized and executed.",
        "subsections": []
      },
      {
        "level": 2,
        "title": "AI Metadata",
        "content": "**Template Version:** 2.1\n**AI Processing Level:** High\n**Required Context:** Git, CI/CD, testing, deployment, project management\n**Validation Required:** Yes\n**Code Generation:** Supported\n\n**Dependencies:**\n- `../guide_docs/Core%20Principles.json.replace(\".json\", \".json\")` - Decision-making frameworks\n- `../guide_docs/Language-Specific/Python%20Testing%20Guide.json.replace(\".json\", \".json\")` - Testing patterns\n- `../guide_docs/Domain-Specific/Database%20Management%20Guide.json.replace(\".json\", \".json\")` - Database patterns\n- `Architecture%20Overview.json.replace(\".json\", \".json\")` - System architecture\n- `Common%20Patterns.json.replace(\".json\", \".json\")` - Project-specific patterns\n\n**Validation Rules:**\n- All code changes must follow Git workflow and branching strategy\n- All commits must include proper commit messages and validation\n- All changes must pass automated testing before deployment\n- All deployments must follow proper environment promotion\n- All documentation must be updated with code changes",
        "subsections": []
      },
      {
        "level": 2,
        "title": "Overview",
        "content": "**Document Purpose:** Development workflow standards and procedures for the CreamPie project\n**Scope:** Git workflow, testing, CI/CD, deployment, and project management\n**Target Users:** AI assistants and developers working on the project\n**Last Updated:** Current\n\n**AI Context:** This guide provides the foundational development workflow that must be followed for all code changes and deployments in the project. It ensures consistent, reliable, and maintainable development practices.",
        "subsections": []
      },
      {
        "level": 2,
        "title": "1. Git Workflow",
        "content": "",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Branching Strategy",
        "content": "```bash",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Main branches",
        "content": "main                    # Production-ready code\ndevelop                 # Integration branch for features\nstaging                 # Pre-production testing",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Feature branches",
        "content": "feature/feature-name    # New features\nbugfix/bug-description  # Bug fixes\nhotfix/critical-fix     # Critical production fixes\nrelease/version-number  # Release preparation\n```\n\nThis branching strategy will inform all Git branch naming and organization.\n\nAll branches must follow this naming convention and purpose.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Commit Message Standards",
        "content": "```bash",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Commit message format",
        "content": "<type>(<scope>): <description>\n\n[optional body]\n\n[optional footer]",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Types",
        "content": "feat:     New feature\nfix:      Bug fix\ndocs:     Documentation changes\nstyle:    Code style changes (formatting, etc.)\nrefactor: Code refactoring\ntest:     Adding or updating tests\nchore:    Maintenance tasks",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Examples",
        "content": "feat(auth): add JWT authentication system\nfix(api): resolve rate limiting issue in stock data endpoint\ndocs(readme): update installation instructions\ntest(stock-data): add unit tests for data processor\nrefactor(ui): extract reusable button component\nchore(deps): update dependencies to latest versions\n```\n\nThis commit message format will inform all Git commit message creation.\n\nAll commits must follow this format with proper type and description.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Git Workflow Commands",
        "content": "```bash",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Start new feature",
        "content": "git checkout develop\ngit pull origin develop\ngit checkout -b feature/new-feature-name",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Make changes and commit",
        "content": "git add .\ngit commit -m \"feat(scope): descriptive commit message\"",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Push feature branch",
        "content": "git push origin feature/new-feature-name",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Create pull request",
        "content": "",
        "subsections": []
      },
      {
        "level": 1,
        "title": "- Target: develop",
        "content": "",
        "subsections": []
      },
      {
        "level": 1,
        "title": "- Include description of changes",
        "content": "",
        "subsections": []
      },
      {
        "level": 1,
        "title": "- Request code review",
        "content": "",
        "subsections": []
      },
      {
        "level": 1,
        "title": "After approval, merge to develop",
        "content": "git checkout develop\ngit pull origin develop\ngit merge feature/new-feature-name\ngit push origin develop",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Clean up feature branch",
        "content": "git branch -d feature/new-feature-name\ngit push origin --delete feature/new-feature-name\n```\n\nThis Git workflow will inform all version control operations.\n\nAll Git operations must follow this workflow sequence.",
        "subsections": []
      },
      {
        "level": 2,
        "title": "2. Code Review Process",
        "content": "",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Pull Request Standards",
        "content": "```markdown",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Pull Request Template",
        "content": "",
        "subsections": []
      },
      {
        "level": 2,
        "title": "Description",
        "content": "Brief description of changes made",
        "subsections": []
      },
      {
        "level": 2,
        "title": "Type of Change",
        "content": "- [ ] Bug fix\n- [ ] New feature\n- [ ] Breaking change\n- [ ] Documentation update",
        "subsections": []
      },
      {
        "level": 2,
        "title": "Testing",
        "content": "- [ ] Unit tests pass\n- [ ] Integration tests pass\n- [ ] Manual testing completed\n- [ ] No new warnings",
        "subsections": []
      },
      {
        "level": 2,
        "title": "Checklist",
        "content": "- [ ] Code follows style guidelines\n- [ ] Self-review completed\n- [ ] Documentation updated\n- [ ] No console errors\n- [ ] Performance impact considered",
        "subsections": []
      },
      {
        "level": 2,
        "title": "Screenshots (if applicable)",
        "content": "Add screenshots for UI changes",
        "subsections": []
      },
      {
        "level": 2,
        "title": "Related Issues",
        "content": "Closes #issue-number\n```\n\nThis PR template will inform all pull request creation and review.\n\nAll pull requests must include proper description and checklist completion.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Code Review Guidelines",
        "content": "```markdown",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Code Review Checklist",
        "content": "",
        "subsections": []
      },
      {
        "level": 2,
        "title": "Functionality",
        "content": "- [ ] Code works as intended\n- [ ] Edge cases handled\n- [ ] Error handling implemented\n- [ ] Performance considerations",
        "subsections": []
      },
      {
        "level": 2,
        "title": "Code Quality",
        "content": "- [ ] Follows style guidelines\n- [ ] No code duplication\n- [ ] Proper naming conventions\n- [ ] Comments where needed",
        "subsections": []
      },
      {
        "level": 2,
        "title": "Security",
        "content": "- [ ] No security vulnerabilities\n- [ ] Input validation implemented\n- [ ] Sensitive data protected\n- [ ] Authentication/authorization correct",
        "subsections": []
      },
      {
        "level": 2,
        "title": "Testing",
        "content": "- [ ] Tests cover new functionality\n- [ ] Tests pass consistently\n- [ ] Test coverage adequate\n- [ ] Integration tests updated",
        "subsections": []
      },
      {
        "level": 2,
        "title": "Documentation",
        "content": "- [ ] Code is self-documenting\n- [ ] README updated if needed\n- [ ] API documentation updated\n- [ ] Comments explain complex logic\n```\n\nThis review checklist will inform all code review processes.\n\nAll code reviews must follow this checklist for comprehensive evaluation.",
        "subsections": []
      },
      {
        "level": 2,
        "title": "3. Testing Workflow",
        "content": "",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Test Execution",
        "content": "```bash",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Run all tests",
        "content": "poetry run pytest",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Run specific test file",
        "content": "poetry run pytest tests/test_specific_module.py",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Run tests with coverage",
        "content": "poetry run pytest --cov=cream_api --cov-report=html",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Run tests in parallel",
        "content": "poetry run pytest -n auto",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Run tests with verbose output",
        "content": "poetry run pytest -v",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Run only unit tests",
        "content": "poetry run pytest tests/unit/",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Run only integration tests",
        "content": "poetry run pytest tests/integration/",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Run tests matching pattern",
        "content": "poetry run pytest -k \"test_function_name\"\n```\n\nThis test execution pattern will inform all testing procedures.\n\nAll code changes must pass all relevant tests before merging.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Test Coverage Requirements",
        "content": "```yaml",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Coverage thresholds",
        "content": "coverage:\n  global:\n    statements: 80\n    branches: 75\n    functions: 80\n    lines: 80\n\n  modules:\n    cream_api:\n      statements: 85\n      branches: 80\n      functions: 85\n      lines: 85\n\n    cream_ui:\n      statements: 80\n      branches: 75\n      functions: 80\n      lines: 80\n```\n\nThis coverage configuration will inform all test coverage requirements.\n\nAll modules must meet minimum coverage thresholds.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Test Data Management",
        "content": "```python",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Test data patterns",
        "content": "import pytest\nfrom unittest.mock import Mock, patch\n\n@pytest.fixture\ndef sample_stock_data():\n    \"\"\"Provide sample stock data for testing\"\"\"\n    return {\n        \"symbol\": \"AAPL\",\n        \"price\": 150.00,\n        \"change\": 2.50,\n        \"volume\": 1000000,\n        \"date\": \"2024-01-01\"\n    }\n\n@pytest.fixture\ndef mock_api_response():\n    \"\"\"Mock API response for testing\"\"\"\n    return {\n        \"success\": True,\n        \"data\": {\n            \"symbol\": \"AAPL\",\n            \"price\": 150.00\n        }\n    }\n\n@pytest.fixture\ndef test_database():\n    \"\"\"Provide test database connection\"\"\"\n    # Setup test database\n    db = create_test_database()\n    yield db\n    # Cleanup\n    db.close()\n```\n\nThis test data pattern will inform all test fixture implementation.\n\nAll tests must use proper fixtures and mock data.",
        "subsections": []
      },
      {
        "level": 2,
        "title": "4. CI/CD Pipeline",
        "content": "",
        "subsections": []
      },
      {
        "level": 3,
        "title": "GitHub Actions Workflow",
        "content": "```yaml",
        "subsections": []
      },
      {
        "level": 1,
        "title": ".github/workflows/ci.yml",
        "content": "name: CI/CD Pipeline\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main, develop]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: '3.11'\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install poetry\n        poetry install\n\n    - name: Run linting\n      run: |\n        poetry run flake8 cream_api\n        poetry run black --check cream_api\n\n    - name: Run tests\n      run: |\n        poetry run pytest --cov=cream_api --cov-report=xml\n\n    - name: Upload coverage\n      uses: codecov/codecov-action@v3\n      with:\n        file: ./coverage.xml\n\n    - name: Run security scan\n      run: |\n        poetry run bandit -r cream_api/\n\n  build:\n    needs: test\n    runs-on: ubuntu-latest\n    if: github.ref == 'refs/heads/main'\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Build Docker image\n      run: |\n        docker build -t creampie:latest .\n\n    - name: Push to registry\n      run: |\n        echo ${{ secrets.DOCKER_PASSWORD }} | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin\n        docker tag creampie:latest ${{ secrets.DOCKER_REGISTRY }}/creampie:latest\n        docker push ${{ secrets.DOCKER_REGISTRY }}/creampie:latest\n```\n\nThis CI/CD configuration will inform all automated pipeline implementation.\n\nAll code changes must pass CI/CD pipeline before deployment.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Deployment Stages",
        "content": "```yaml",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Deployment configuration",
        "content": "deployment:\n  stages:\n    - name: development\n      branch: develop\n      environment: dev\n      auto_deploy: true\n      tests: required\n\n    - name: staging\n      branch: staging\n      environment: staging\n      auto_deploy: false\n      tests: required\n      manual_approval: true\n\n    - name: production\n      branch: main\n      environment: production\n      auto_deploy: false\n      tests: required\n      manual_approval: true\n      rollback: enabled\n```\n\nThis deployment configuration will inform all deployment stage management.\n\nAll deployments must follow proper stage progression and approval.",
        "subsections": []
      },
      {
        "level": 2,
        "title": "5. Environment Management",
        "content": "",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Environment Configuration",
        "content": "```bash",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Environment variables structure",
        "content": "",
        "subsections": []
      },
      {
        "level": 1,
        "title": ".env.development",
        "content": "DATABASE_URL=postgresql://user:pass@localhost:5432/creampie_dev\nREDIS_URL=redis://localhost:6379/0\nAPI_KEY=dev_api_key\nLOG_LEVEL=DEBUG\nENVIRONMENT=development",
        "subsections": []
      },
      {
        "level": 1,
        "title": ".env.staging",
        "content": "DATABASE_URL=postgresql://user:pass@staging-db:5432/creampie_staging\nREDIS_URL=redis://staging-redis:6379/0\nAPI_KEY=staging_api_key\nLOG_LEVEL=INFO\nENVIRONMENT=staging",
        "subsections": []
      },
      {
        "level": 1,
        "title": ".env.production",
        "content": "DATABASE_URL=postgresql://user:pass@prod-db:5432/creampie_prod\nREDIS_URL=redis://prod-redis:6379/0\nAPI_KEY=prod_api_key\nLOG_LEVEL=WARNING\nENVIRONMENT=production\n```\n\nThis environment configuration will inform all environment variable management.\n\nAll environments must have proper configuration and secrets management.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Database Migrations",
        "content": "```bash",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Migration workflow",
        "content": "",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Create new migration",
        "content": "poetry run alembic revision --autogenerate -m \"description of changes\"",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Apply migrations",
        "content": "poetry run alembic upgrade head",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Rollback migration",
        "content": "poetry run alembic downgrade -1",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Check migration status",
        "content": "poetry run alembic current",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Generate migration script",
        "content": "poetry run alembic revision -m \"manual migration\"\n```\n\nThis migration workflow will inform all database schema changes.\n\nAll database changes must use proper migration procedures.",
        "subsections": []
      },
      {
        "level": 2,
        "title": "6. Monitoring and Logging",
        "content": "",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Application Monitoring",
        "content": "```python",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Monitoring configuration",
        "content": "import logging\nfrom prometheus_client import Counter, Histogram, start_http_server",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Metrics",
        "content": "REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint'])\nREQUEST_DURATION = Histogram('http_request_duration_seconds', 'HTTP request duration')",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Logging configuration",
        "content": "logging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('app.log'),\n        logging.StreamHandler()\n    ]\n)",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Health check endpoint",
        "content": "@app.get(\"/health\")\nasync def health_check():\n    return {\n        \"status\": \"healthy\",\n        \"timestamp\": datetime.utcnow(),\n        \"version\": \"1.0.0\"\n    }\n```\n\nThis monitoring configuration will inform all application monitoring implementation.\n\nAll applications must include proper monitoring and health checks.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Error Tracking",
        "content": "```python",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Error tracking configuration",
        "content": "import sentry_sdk\nfrom sentry_sdk.integrations.fastapi import FastApiIntegration\n\nsentry_sdk.init(\n    dsn=os.getenv(\"SENTRY_DSN\"),\n    integrations=[FastApiIntegration()],\n    traces_sample_rate=1.0,\n    environment=os.getenv(\"ENVIRONMENT\", \"development\")\n)",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Custom error handling",
        "content": "@app.exception_handler(Exception)\nasync def global_exception_handler(request: Request, exc: Exception):\n    # Log error\n    logger.error(f\"Unhandled exception: {exc}\", exc_info=True)\n\n    # Send to error tracking\n    sentry_sdk.capture_exception(exc)\n\n    return JSONResponse(\n        status_code=500,\n        content={\"detail\": \"Internal server error\"}\n    )\n```\n\nThis error tracking configuration will inform all error handling implementation.\n\nAll applications must include proper error tracking and handling.",
        "subsections": []
      },
      {
        "level": 2,
        "title": "7. Documentation Standards",
        "content": "",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Code Documentation",
        "content": "```python",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Function documentation",
        "content": "def process_stock_data(symbol: str, data: dict) -> dict:\n    \"\"\"\n    Process raw stock data and return formatted results.\n\n    Args:\n        symbol (str): Stock symbol (e.g., 'AAPL')\n        data (dict): Raw stock data from API\n\n    Returns:\n        dict: Processed stock data with calculated fields\n\n    Raises:\n        ValueError: If symbol is invalid or data is malformed\n        ProcessingError: If data processing fails\n\n    Example:\n        >>> data = {\"price\": 150.00, \"volume\": 1000000}\n        >>> result = process_stock_data(\"AAPL\", data)\n        >>> print(result[\"formatted_price\"])\n        '$150.00'\n    \"\"\"\n    # Implementation here\n    pass\n```\n\nThis documentation pattern will inform all code documentation implementation.\n\nAll functions must include proper docstrings and examples.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "API Documentation",
        "content": "```python",
        "subsections": []
      },
      {
        "level": 1,
        "title": "FastAPI documentation",
        "content": "from fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\n\napp = FastAPI(\n    title=\"CreamPie API\",\n    description=\"Stock data processing and analysis API\",\n    version=\"1.0.0\",\n    docs_url=\"/docs\",\n    redoc_url=\"/redoc\"\n)\n\nclass StockData(BaseModel):\n    \"\"\"Stock data model for API requests\"\"\"\n    symbol: str = Field(..., description=\"Stock symbol (e.g., AAPL)\")\n    date: str = Field(..., description=\"Date in YYYY-MM-DD format\")\n\n    class Config:\n        schema_extra = {\n            \"example\": {\n                \"symbol\": \"AAPL\",\n                \"date\": \"2024-01-01\"\n            }\n        }\n\n@app.get(\"/api/stock/{symbol}\", response_model=StockData)\nasync def get_stock_data(\n    symbol: str = Path(..., description=\"Stock symbol to retrieve\"),\n    date: str = Query(..., description=\"Date for stock data\")\n):\n    \"\"\"\n    Retrieve stock data for a given symbol and date.\n\n    - **symbol**: Stock symbol (e.g., AAPL, TSLA)\n    - **date**: Date in YYYY-MM-DD format\n\n    Returns stock price, volume, and other market data.\n    \"\"\"\n    # Implementation here\n    pass\n```\n\nThis API documentation pattern will inform all API endpoint documentation.\n\nAll API endpoints must include proper documentation and examples.",
        "subsections": []
      },
      {
        "level": 2,
        "title": "Implementation Guidelines",
        "content": "",
        "subsections": []
      },
      {
        "level": 3,
        "title": "For AI Assistants",
        "content": "1. **Follow these patterns** for all development workflow implementation\n2. **Use proper Git workflow** with meaningful commit messages\n3. **Include comprehensive testing** with proper coverage\n4. **Follow CI/CD pipeline** requirements and validation\n5. **Implement proper monitoring** and error tracking\n6. **Update documentation** with all code changes\n7. **Follow security best practices** for all deployments\n8. **Use proper environment management** for all stages",
        "subsections": []
      },
      {
        "level": 3,
        "title": "For Human Developers",
        "content": "1. **Reference these patterns** when working on the project\n2. **Follow Git workflow** for all code changes\n3. **Write comprehensive tests** for new functionality\n4. **Use CI/CD pipeline** for automated validation\n5. **Monitor application health** and performance\n6. **Keep documentation updated** with changes\n7. **Follow security guidelines** for production deployments",
        "subsections": []
      },
      {
        "level": 2,
        "title": "Quality Assurance",
        "content": "",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Development Standards",
        "content": "- All code changes must follow Git workflow and branching strategy\n- All commits must include proper commit messages and validation\n- All changes must pass automated testing before deployment\n- All deployments must follow proper environment promotion\n- All documentation must be updated with code changes",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Testing Standards",
        "content": "- Unit tests must cover all new functionality\n- Integration tests must validate component interactions\n- Test coverage must meet minimum thresholds\n- Performance tests must be included for critical paths\n- Security tests must validate input handling",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Deployment Standards",
        "content": "- All deployments must pass CI/CD pipeline validation\n- Environment promotion must follow proper sequence\n- Rollback procedures must be tested and documented\n- Monitoring and alerting must be configured\n- Security scanning must be performed",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Documentation Standards",
        "content": "- Code must be self-documenting with proper comments\n- API documentation must be comprehensive and up-to-date\n- README files must include setup and usage instructions\n- Architecture documentation must reflect current state\n- Change logs must be maintained for all releases\n\n---\n\n**AI Quality Checklist**: Before implementing development workflow changes, ensure:\n- [x] Git workflow follows branching strategy and commit standards\n- [x] Code review process includes comprehensive checklist\n- [x] Testing workflow covers all required test types\n- [x] CI/CD pipeline includes all validation steps\n- [x] Environment management follows proper configuration\n- [x] Monitoring and logging are properly configured\n- [x] Documentation standards are followed for all changes\n- [x] Security best practices are implemented throughout",
        "subsections": []
      }
    ],
    "code_blocks": [
      {
        "language": "bash",
        "code": "# Main branches\nmain                    # Production-ready code\ndevelop                 # Integration branch for features\nstaging                 # Pre-production testing\n\n# Feature branches\nfeature/feature-name    # New features\nbugfix/bug-description  # Bug fixes\nhotfix/critical-fix     # Critical production fixes\nrelease/version-number  # Release preparation"
      },
      {
        "language": "bash",
        "code": "# Commit message format\n<type>(<scope>): <description>\n\n[optional body]\n\n[optional footer]\n\n# Types\nfeat:     New feature\nfix:      Bug fix\ndocs:     Documentation changes\nstyle:    Code style changes (formatting, etc.)\nrefactor: Code refactoring\ntest:     Adding or updating tests\nchore:    Maintenance tasks\n\n# Examples\nfeat(auth): add JWT authentication system\nfix(api): resolve rate limiting issue in stock data endpoint\ndocs(readme): update installation instructions\ntest(stock-data): add unit tests for data processor\nrefactor(ui): extract reusable button component\nchore(deps): update dependencies to latest versions"
      },
      {
        "language": "bash",
        "code": "# Start new feature\ngit checkout develop\ngit pull origin develop\ngit checkout -b feature/new-feature-name\n\n# Make changes and commit\ngit add .\ngit commit -m \"feat(scope): descriptive commit message\"\n\n# Push feature branch\ngit push origin feature/new-feature-name\n\n# Create pull request\n# - Target: develop\n# - Include description of changes\n# - Request code review\n\n# After approval, merge to develop\ngit checkout develop\ngit pull origin develop\ngit merge feature/new-feature-name\ngit push origin develop\n\n# Clean up feature branch\ngit branch -d feature/new-feature-name\ngit push origin --delete feature/new-feature-name"
      },
      {
        "language": "markdown",
        "code": "# Pull Request Template\n\n## Description\nBrief description of changes made\n\n## Type of Change\n- [ ] Bug fix\n- [ ] New feature\n- [ ] Breaking change\n- [ ] Documentation update\n\n## Testing\n- [ ] Unit tests pass\n- [ ] Integration tests pass\n- [ ] Manual testing completed\n- [ ] No new warnings\n\n## Checklist\n- [ ] Code follows style guidelines\n- [ ] Self-review completed\n- [ ] Documentation updated\n- [ ] No console errors\n- [ ] Performance impact considered\n\n## Screenshots (if applicable)\nAdd screenshots for UI changes\n\n## Related Issues\nCloses #issue-number"
      },
      {
        "language": "markdown",
        "code": "# Code Review Checklist\n\n## Functionality\n- [ ] Code works as intended\n- [ ] Edge cases handled\n- [ ] Error handling implemented\n- [ ] Performance considerations\n\n## Code Quality\n- [ ] Follows style guidelines\n- [ ] No code duplication\n- [ ] Proper naming conventions\n- [ ] Comments where needed\n\n## Security\n- [ ] No security vulnerabilities\n- [ ] Input validation implemented\n- [ ] Sensitive data protected\n- [ ] Authentication/authorization correct\n\n## Testing\n- [ ] Tests cover new functionality\n- [ ] Tests pass consistently\n- [ ] Test coverage adequate\n- [ ] Integration tests updated\n\n## Documentation\n- [ ] Code is self-documenting\n- [ ] README updated if needed\n- [ ] API documentation updated\n- [ ] Comments explain complex logic"
      },
      {
        "language": "bash",
        "code": "# Run all tests\npoetry run pytest\n\n# Run specific test file\npoetry run pytest tests/test_specific_module.py\n\n# Run tests with coverage\npoetry run pytest --cov=cream_api --cov-report=html\n\n# Run tests in parallel\npoetry run pytest -n auto\n\n# Run tests with verbose output\npoetry run pytest -v\n\n# Run only unit tests\npoetry run pytest tests/unit/\n\n# Run only integration tests\npoetry run pytest tests/integration/\n\n# Run tests matching pattern\npoetry run pytest -k \"test_function_name\""
      },
      {
        "language": "yaml",
        "code": "# Coverage thresholds\ncoverage:\n  global:\n    statements: 80\n    branches: 75\n    functions: 80\n    lines: 80\n\n  modules:\n    cream_api:\n      statements: 85\n      branches: 80\n      functions: 85\n      lines: 85\n\n    cream_ui:\n      statements: 80\n      branches: 75\n      functions: 80\n      lines: 80"
      },
      {
        "language": "python",
        "code": "# Test data patterns\nimport pytest\nfrom unittest.mock import Mock, patch\n\n@pytest.fixture\ndef sample_stock_data():\n    \"\"\"Provide sample stock data for testing\"\"\"\n    return {\n        \"symbol\": \"AAPL\",\n        \"price\": 150.00,\n        \"change\": 2.50,\n        \"volume\": 1000000,\n        \"date\": \"2024-01-01\"\n    }\n\n@pytest.fixture\ndef mock_api_response():\n    \"\"\"Mock API response for testing\"\"\"\n    return {\n        \"success\": True,\n        \"data\": {\n            \"symbol\": \"AAPL\",\n            \"price\": 150.00\n        }\n    }\n\n@pytest.fixture\ndef test_database():\n    \"\"\"Provide test database connection\"\"\"\n    # Setup test database\n    db = create_test_database()\n    yield db\n    # Cleanup\n    db.close()"
      },
      {
        "language": "yaml",
        "code": "# .github/workflows/ci.yml\nname: CI/CD Pipeline\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main, develop]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: '3.11'\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install poetry\n        poetry install\n\n    - name: Run linting\n      run: |\n        poetry run flake8 cream_api\n        poetry run black --check cream_api\n\n    - name: Run tests\n      run: |\n        poetry run pytest --cov=cream_api --cov-report=xml\n\n    - name: Upload coverage\n      uses: codecov/codecov-action@v3\n      with:\n        file: ./coverage.xml\n\n    - name: Run security scan\n      run: |\n        poetry run bandit -r cream_api/\n\n  build:\n    needs: test\n    runs-on: ubuntu-latest\n    if: github.ref == 'refs/heads/main'\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Build Docker image\n      run: |\n        docker build -t creampie:latest .\n\n    - name: Push to registry\n      run: |\n        echo ${{ secrets.DOCKER_PASSWORD }} | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin\n        docker tag creampie:latest ${{ secrets.DOCKER_REGISTRY }}/creampie:latest\n        docker push ${{ secrets.DOCKER_REGISTRY }}/creampie:latest"
      },
      {
        "language": "yaml",
        "code": "# Deployment configuration\ndeployment:\n  stages:\n    - name: development\n      branch: develop\n      environment: dev\n      auto_deploy: true\n      tests: required\n\n    - name: staging\n      branch: staging\n      environment: staging\n      auto_deploy: false\n      tests: required\n      manual_approval: true\n\n    - name: production\n      branch: main\n      environment: production\n      auto_deploy: false\n      tests: required\n      manual_approval: true\n      rollback: enabled"
      },
      {
        "language": "bash",
        "code": "# Environment variables structure\n# .env.development\nDATABASE_URL=postgresql://user:pass@localhost:5432/creampie_dev\nREDIS_URL=redis://localhost:6379/0\nAPI_KEY=dev_api_key\nLOG_LEVEL=DEBUG\nENVIRONMENT=development\n\n# .env.staging\nDATABASE_URL=postgresql://user:pass@staging-db:5432/creampie_staging\nREDIS_URL=redis://staging-redis:6379/0\nAPI_KEY=staging_api_key\nLOG_LEVEL=INFO\nENVIRONMENT=staging\n\n# .env.production\nDATABASE_URL=postgresql://user:pass@prod-db:5432/creampie_prod\nREDIS_URL=redis://prod-redis:6379/0\nAPI_KEY=prod_api_key\nLOG_LEVEL=WARNING\nENVIRONMENT=production"
      },
      {
        "language": "bash",
        "code": "# Migration workflow\n# Create new migration\npoetry run alembic revision --autogenerate -m \"description of changes\"\n\n# Apply migrations\npoetry run alembic upgrade head\n\n# Rollback migration\npoetry run alembic downgrade -1\n\n# Check migration status\npoetry run alembic current\n\n# Generate migration script\npoetry run alembic revision -m \"manual migration\""
      },
      {
        "language": "python",
        "code": "# Monitoring configuration\nimport logging\nfrom prometheus_client import Counter, Histogram, start_http_server\n\n# Metrics\nREQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint'])\nREQUEST_DURATION = Histogram('http_request_duration_seconds', 'HTTP request duration')\n\n# Logging configuration\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('app.log'),\n        logging.StreamHandler()\n    ]\n)\n\n# Health check endpoint\n@app.get(\"/health\")\nasync def health_check():\n    return {\n        \"status\": \"healthy\",\n        \"timestamp\": datetime.utcnow(),\n        \"version\": \"1.0.0\"\n    }"
      },
      {
        "language": "python",
        "code": "# Error tracking configuration\nimport sentry_sdk\nfrom sentry_sdk.integrations.fastapi import FastApiIntegration\n\nsentry_sdk.init(\n    dsn=os.getenv(\"SENTRY_DSN\"),\n    integrations=[FastApiIntegration()],\n    traces_sample_rate=1.0,\n    environment=os.getenv(\"ENVIRONMENT\", \"development\")\n)\n\n# Custom error handling\n@app.exception_handler(Exception)\nasync def global_exception_handler(request: Request, exc: Exception):\n    # Log error\n    logger.error(f\"Unhandled exception: {exc}\", exc_info=True)\n\n    # Send to error tracking\n    sentry_sdk.capture_exception(exc)\n\n    return JSONResponse(\n        status_code=500,\n        content={\"detail\": \"Internal server error\"}\n    )"
      },
      {
        "language": "python",
        "code": "# Function documentation\ndef process_stock_data(symbol: str, data: dict) -> dict:\n    \"\"\"\n    Process raw stock data and return formatted results.\n\n    Args:\n        symbol (str): Stock symbol (e.g., 'AAPL')\n        data (dict): Raw stock data from API\n\n    Returns:\n        dict: Processed stock data with calculated fields\n\n    Raises:\n        ValueError: If symbol is invalid or data is malformed\n        ProcessingError: If data processing fails\n\n    Example:\n        >>> data = {\"price\": 150.00, \"volume\": 1000000}\n        >>> result = process_stock_data(\"AAPL\", data)\n        >>> print(result[\"formatted_price\"])\n        '$150.00'\n    \"\"\"\n    # Implementation here\n    pass"
      },
      {
        "language": "python",
        "code": "# FastAPI documentation\nfrom fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\n\napp = FastAPI(\n    title=\"CreamPie API\",\n    description=\"Stock data processing and analysis API\",\n    version=\"1.0.0\",\n    docs_url=\"/docs\",\n    redoc_url=\"/redoc\"\n)\n\nclass StockData(BaseModel):\n    \"\"\"Stock data model for API requests\"\"\"\n    symbol: str = Field(..., description=\"Stock symbol (e.g., AAPL)\")\n    date: str = Field(..., description=\"Date in YYYY-MM-DD format\")\n\n    class Config:\n        schema_extra = {\n            \"example\": {\n                \"symbol\": \"AAPL\",\n                \"date\": \"2024-01-01\"\n            }\n        }\n\n@app.get(\"/api/stock/{symbol}\", response_model=StockData)\nasync def get_stock_data(\n    symbol: str = Path(..., description=\"Stock symbol to retrieve\"),\n    date: str = Query(..., description=\"Date for stock data\")\n):\n    \"\"\"\n    Retrieve stock data for a given symbol and date.\n\n    - **symbol**: Stock symbol (e.g., AAPL, TSLA)\n    - **date**: Date in YYYY-MM-DD format\n\n    Returns stock price, volume, and other market data.\n    \"\"\"\n    # Implementation here\n    pass"
      }
    ],
    "links": [
      {
        "type": "code_reference",
        "text": "../guide_docs/Core%20Principles.md"
      },
      {
        "type": "code_reference",
        "text": "../guide_docs/Language-Specific/Python%20Testing%20Guide.md"
      },
      {
        "type": "code_reference",
        "text": "../guide_docs/Domain-Specific/Database%20Management%20Guide.md"
      },
      {
        "type": "code_reference",
        "text": "Architecture%20Overview.md"
      },
      {
        "type": "code_reference",
        "text": "Common%20Patterns.md"
      },
      {
        "type": "code_reference",
        "text": "\n\nThis branching strategy will inform all Git branch naming and organization.\n\nAll branches must follow this naming convention and purpose.\n\n### Commit Message Standards\n"
      },
      {
        "type": "code_reference",
        "text": "bash\n# Commit message format\n<type>(<scope>): <description>\n\n[optional body]\n\n[optional footer]\n\n# Types\nfeat:     New feature\nfix:      Bug fix\ndocs:     Documentation changes\nstyle:    Code style changes (formatting, etc.)\nrefactor: Code refactoring\ntest:     Adding or updating tests\nchore:    Maintenance tasks\n\n# Examples\nfeat(auth): add JWT authentication system\nfix(api): resolve rate limiting issue in stock data endpoint\ndocs(readme): update installation instructions\ntest(stock-data): add unit tests for data processor\nrefactor(ui): extract reusable button component\nchore(deps): update dependencies to latest versions\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThis commit message format will inform all Git commit message creation.\n\nAll commits must follow this format with proper type and description.\n\n### Git Workflow Commands\n"
      },
      {
        "type": "code_reference",
        "text": "bash\n# Start new feature\ngit checkout develop\ngit pull origin develop\ngit checkout -b feature/new-feature-name\n\n# Make changes and commit\ngit add .\ngit commit -m \"feat(scope): descriptive commit message\"\n\n# Push feature branch\ngit push origin feature/new-feature-name\n\n# Create pull request\n# - Target: develop\n# - Include description of changes\n# - Request code review\n\n# After approval, merge to develop\ngit checkout develop\ngit pull origin develop\ngit merge feature/new-feature-name\ngit push origin develop\n\n# Clean up feature branch\ngit branch -d feature/new-feature-name\ngit push origin --delete feature/new-feature-name\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThis Git workflow will inform all version control operations.\n\nAll Git operations must follow this workflow sequence.\n\n## 2. Code Review Process\n\n### Pull Request Standards\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThis PR template will inform all pull request creation and review.\n\nAll pull requests must include proper description and checklist completion.\n\n### Code Review Guidelines\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThis review checklist will inform all code review processes.\n\nAll code reviews must follow this checklist for comprehensive evaluation.\n\n## 3. Testing Workflow\n\n### Test Execution\n"
      },
      {
        "type": "code_reference",
        "text": "bash\n# Run all tests\npoetry run pytest\n\n# Run specific test file\npoetry run pytest tests/test_specific_module.py\n\n# Run tests with coverage\npoetry run pytest --cov=cream_api --cov-report=html\n\n# Run tests in parallel\npoetry run pytest -n auto\n\n# Run tests with verbose output\npoetry run pytest -v\n\n# Run only unit tests\npoetry run pytest tests/unit/\n\n# Run only integration tests\npoetry run pytest tests/integration/\n\n# Run tests matching pattern\npoetry run pytest -k \"test_function_name\"\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThis test execution pattern will inform all testing procedures.\n\nAll code changes must pass all relevant tests before merging.\n\n### Test Coverage Requirements\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThis coverage configuration will inform all test coverage requirements.\n\nAll modules must meet minimum coverage thresholds.\n\n### Test Data Management\n"
      },
      {
        "type": "code_reference",
        "text": "python\n# Test data patterns\nimport pytest\nfrom unittest.mock import Mock, patch\n\n@pytest.fixture\ndef sample_stock_data():\n    \"\"\"Provide sample stock data for testing\"\"\"\n    return {\n        \"symbol\": \"AAPL\",\n        \"price\": 150.00,\n        \"change\": 2.50,\n        \"volume\": 1000000,\n        \"date\": \"2024-01-01\"\n    }\n\n@pytest.fixture\ndef mock_api_response():\n    \"\"\"Mock API response for testing\"\"\"\n    return {\n        \"success\": True,\n        \"data\": {\n            \"symbol\": \"AAPL\",\n            \"price\": 150.00\n        }\n    }\n\n@pytest.fixture\ndef test_database():\n    \"\"\"Provide test database connection\"\"\"\n    # Setup test database\n    db = create_test_database()\n    yield db\n    # Cleanup\n    db.close()\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThis test data pattern will inform all test fixture implementation.\n\nAll tests must use proper fixtures and mock data.\n\n## 4. CI/CD Pipeline\n\n### GitHub Actions Workflow\n"
      },
      {
        "type": "code_reference",
        "text": "yaml\n# .github/workflows/ci.yml\nname: CI/CD Pipeline\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main, develop]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: '3.11'\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install poetry\n        poetry install\n\n    - name: Run linting\n      run: |\n        poetry run flake8 cream_api\n        poetry run black --check cream_api\n\n    - name: Run tests\n      run: |\n        poetry run pytest --cov=cream_api --cov-report=xml\n\n    - name: Upload coverage\n      uses: codecov/codecov-action@v3\n      with:\n        file: ./coverage.xml\n\n    - name: Run security scan\n      run: |\n        poetry run bandit -r cream_api/\n\n  build:\n    needs: test\n    runs-on: ubuntu-latest\n    if: github.ref == 'refs/heads/main'\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Build Docker image\n      run: |\n        docker build -t creampie:latest .\n\n    - name: Push to registry\n      run: |\n        echo ${{ secrets.DOCKER_PASSWORD }} | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin\n        docker tag creampie:latest ${{ secrets.DOCKER_REGISTRY }}/creampie:latest\n        docker push ${{ secrets.DOCKER_REGISTRY }}/creampie:latest\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThis CI/CD configuration will inform all automated pipeline implementation.\n\nAll code changes must pass CI/CD pipeline before deployment.\n\n### Deployment Stages\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThis deployment configuration will inform all deployment stage management.\n\nAll deployments must follow proper stage progression and approval.\n\n## 5. Environment Management\n\n### Environment Configuration\n"
      },
      {
        "type": "code_reference",
        "text": "bash\n# Environment variables structure\n# .env.development\nDATABASE_URL=postgresql://user:pass@localhost:5432/creampie_dev\nREDIS_URL=redis://localhost:6379/0\nAPI_KEY=dev_api_key\nLOG_LEVEL=DEBUG\nENVIRONMENT=development\n\n# .env.staging\nDATABASE_URL=postgresql://user:pass@staging-db:5432/creampie_staging\nREDIS_URL=redis://staging-redis:6379/0\nAPI_KEY=staging_api_key\nLOG_LEVEL=INFO\nENVIRONMENT=staging\n\n# .env.production\nDATABASE_URL=postgresql://user:pass@prod-db:5432/creampie_prod\nREDIS_URL=redis://prod-redis:6379/0\nAPI_KEY=prod_api_key\nLOG_LEVEL=WARNING\nENVIRONMENT=production\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThis environment configuration will inform all environment variable management.\n\nAll environments must have proper configuration and secrets management.\n\n### Database Migrations\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThis migration workflow will inform all database schema changes.\n\nAll database changes must use proper migration procedures.\n\n## 6. Monitoring and Logging\n\n### Application Monitoring\n"
      },
      {
        "type": "code_reference",
        "text": "python\n# Monitoring configuration\nimport logging\nfrom prometheus_client import Counter, Histogram, start_http_server\n\n# Metrics\nREQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint'])\nREQUEST_DURATION = Histogram('http_request_duration_seconds', 'HTTP request duration')\n\n# Logging configuration\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('app.log'),\n        logging.StreamHandler()\n    ]\n)\n\n# Health check endpoint\n@app.get(\"/health\")\nasync def health_check():\n    return {\n        \"status\": \"healthy\",\n        \"timestamp\": datetime.utcnow(),\n        \"version\": \"1.0.0\"\n    }\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThis monitoring configuration will inform all application monitoring implementation.\n\nAll applications must include proper monitoring and health checks.\n\n### Error Tracking\n"
      },
      {
        "type": "code_reference",
        "text": "python\n# Error tracking configuration\nimport sentry_sdk\nfrom sentry_sdk.integrations.fastapi import FastApiIntegration\n\nsentry_sdk.init(\n    dsn=os.getenv(\"SENTRY_DSN\"),\n    integrations=[FastApiIntegration()],\n    traces_sample_rate=1.0,\n    environment=os.getenv(\"ENVIRONMENT\", \"development\")\n)\n\n# Custom error handling\n@app.exception_handler(Exception)\nasync def global_exception_handler(request: Request, exc: Exception):\n    # Log error\n    logger.error(f\"Unhandled exception: {exc}\", exc_info=True)\n\n    # Send to error tracking\n    sentry_sdk.capture_exception(exc)\n\n    return JSONResponse(\n        status_code=500,\n        content={\"detail\": \"Internal server error\"}\n    )\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThis error tracking configuration will inform all error handling implementation.\n\nAll applications must include proper error tracking and handling.\n\n## 7. Documentation Standards\n\n### Code Documentation\n"
      },
      {
        "type": "code_reference",
        "text": "python\n# Function documentation\ndef process_stock_data(symbol: str, data: dict) -> dict:\n    \"\"\"\n    Process raw stock data and return formatted results.\n\n    Args:\n        symbol (str): Stock symbol (e.g., 'AAPL')\n        data (dict): Raw stock data from API\n\n    Returns:\n        dict: Processed stock data with calculated fields\n\n    Raises:\n        ValueError: If symbol is invalid or data is malformed\n        ProcessingError: If data processing fails\n\n    Example:\n        >>> data = {\"price\": 150.00, \"volume\": 1000000}\n        >>> result = process_stock_data(\"AAPL\", data)\n        >>> print(result[\"formatted_price\"])\n        '$150.00'\n    \"\"\"\n    # Implementation here\n    pass\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThis documentation pattern will inform all code documentation implementation.\n\nAll functions must include proper docstrings and examples.\n\n### API Documentation\n"
      },
      {
        "type": "code_reference",
        "text": "python\n# FastAPI documentation\nfrom fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\n\napp = FastAPI(\n    title=\"CreamPie API\",\n    description=\"Stock data processing and analysis API\",\n    version=\"1.0.0\",\n    docs_url=\"/docs\",\n    redoc_url=\"/redoc\"\n)\n\nclass StockData(BaseModel):\n    \"\"\"Stock data model for API requests\"\"\"\n    symbol: str = Field(..., description=\"Stock symbol (e.g., AAPL)\")\n    date: str = Field(..., description=\"Date in YYYY-MM-DD format\")\n\n    class Config:\n        schema_extra = {\n            \"example\": {\n                \"symbol\": \"AAPL\",\n                \"date\": \"2024-01-01\"\n            }\n        }\n\n@app.get(\"/api/stock/{symbol}\", response_model=StockData)\nasync def get_stock_data(\n    symbol: str = Path(..., description=\"Stock symbol to retrieve\"),\n    date: str = Query(..., description=\"Date for stock data\")\n):\n    \"\"\"\n    Retrieve stock data for a given symbol and date.\n\n    - **symbol**: Stock symbol (e.g., AAPL, TSLA)\n    - **date**: Date in YYYY-MM-DD format\n\n    Returns stock price, volume, and other market data.\n    \"\"\"\n    # Implementation here\n    pass\n"
      }
    ],
    "raw_content": "# Development Workflow\n\n> This document describes the development workflow and processes used in the project. Use this for understanding how development tasks are organized and executed.\n\n## AI Metadata\n\n**Template Version:** 2.1\n**AI Processing Level:** High\n**Required Context:** Git, CI/CD, testing, deployment, project management\n**Validation Required:** Yes\n**Code Generation:** Supported\n\n**Dependencies:**\n- `../guide_docs/Core%20Principles.md` - Decision-making frameworks\n- `../guide_docs/Language-Specific/Python%20Testing%20Guide.md` - Testing patterns\n- `../guide_docs/Domain-Specific/Database%20Management%20Guide.md` - Database patterns\n- `Architecture%20Overview.md` - System architecture\n- `Common%20Patterns.md` - Project-specific patterns\n\n**Validation Rules:**\n- All code changes must follow Git workflow and branching strategy\n- All commits must include proper commit messages and validation\n- All changes must pass automated testing before deployment\n- All deployments must follow proper environment promotion\n- All documentation must be updated with code changes\n\n## Overview\n\n**Document Purpose:** Development workflow standards and procedures for the CreamPie project\n**Scope:** Git workflow, testing, CI/CD, deployment, and project management\n**Target Users:** AI assistants and developers working on the project\n**Last Updated:** Current\n\n**AI Context:** This guide provides the foundational development workflow that must be followed for all code changes and deployments in the project. It ensures consistent, reliable, and maintainable development practices.\n\n## 1. Git Workflow\n\n### Branching Strategy\n```bash\n# Main branches\nmain                    # Production-ready code\ndevelop                 # Integration branch for features\nstaging                 # Pre-production testing\n\n# Feature branches\nfeature/feature-name    # New features\nbugfix/bug-description  # Bug fixes\nhotfix/critical-fix     # Critical production fixes\nrelease/version-number  # Release preparation\n```\n\nThis branching strategy will inform all Git branch naming and organization.\n\nAll branches must follow this naming convention and purpose.\n\n### Commit Message Standards\n```bash\n# Commit message format\n<type>(<scope>): <description>\n\n[optional body]\n\n[optional footer]\n\n# Types\nfeat:     New feature\nfix:      Bug fix\ndocs:     Documentation changes\nstyle:    Code style changes (formatting, etc.)\nrefactor: Code refactoring\ntest:     Adding or updating tests\nchore:    Maintenance tasks\n\n# Examples\nfeat(auth): add JWT authentication system\nfix(api): resolve rate limiting issue in stock data endpoint\ndocs(readme): update installation instructions\ntest(stock-data): add unit tests for data processor\nrefactor(ui): extract reusable button component\nchore(deps): update dependencies to latest versions\n```\n\nThis commit message format will inform all Git commit message creation.\n\nAll commits must follow this format with proper type and description.\n\n### Git Workflow Commands\n```bash\n# Start new feature\ngit checkout develop\ngit pull origin develop\ngit checkout -b feature/new-feature-name\n\n# Make changes and commit\ngit add .\ngit commit -m \"feat(scope): descriptive commit message\"\n\n# Push feature branch\ngit push origin feature/new-feature-name\n\n# Create pull request\n# - Target: develop\n# - Include description of changes\n# - Request code review\n\n# After approval, merge to develop\ngit checkout develop\ngit pull origin develop\ngit merge feature/new-feature-name\ngit push origin develop\n\n# Clean up feature branch\ngit branch -d feature/new-feature-name\ngit push origin --delete feature/new-feature-name\n```\n\nThis Git workflow will inform all version control operations.\n\nAll Git operations must follow this workflow sequence.\n\n## 2. Code Review Process\n\n### Pull Request Standards\n```markdown\n# Pull Request Template\n\n## Description\nBrief description of changes made\n\n## Type of Change\n- [ ] Bug fix\n- [ ] New feature\n- [ ] Breaking change\n- [ ] Documentation update\n\n## Testing\n- [ ] Unit tests pass\n- [ ] Integration tests pass\n- [ ] Manual testing completed\n- [ ] No new warnings\n\n## Checklist\n- [ ] Code follows style guidelines\n- [ ] Self-review completed\n- [ ] Documentation updated\n- [ ] No console errors\n- [ ] Performance impact considered\n\n## Screenshots (if applicable)\nAdd screenshots for UI changes\n\n## Related Issues\nCloses #issue-number\n```\n\nThis PR template will inform all pull request creation and review.\n\nAll pull requests must include proper description and checklist completion.\n\n### Code Review Guidelines\n```markdown\n# Code Review Checklist\n\n## Functionality\n- [ ] Code works as intended\n- [ ] Edge cases handled\n- [ ] Error handling implemented\n- [ ] Performance considerations\n\n## Code Quality\n- [ ] Follows style guidelines\n- [ ] No code duplication\n- [ ] Proper naming conventions\n- [ ] Comments where needed\n\n## Security\n- [ ] No security vulnerabilities\n- [ ] Input validation implemented\n- [ ] Sensitive data protected\n- [ ] Authentication/authorization correct\n\n## Testing\n- [ ] Tests cover new functionality\n- [ ] Tests pass consistently\n- [ ] Test coverage adequate\n- [ ] Integration tests updated\n\n## Documentation\n- [ ] Code is self-documenting\n- [ ] README updated if needed\n- [ ] API documentation updated\n- [ ] Comments explain complex logic\n```\n\nThis review checklist will inform all code review processes.\n\nAll code reviews must follow this checklist for comprehensive evaluation.\n\n## 3. Testing Workflow\n\n### Test Execution\n```bash\n# Run all tests\npoetry run pytest\n\n# Run specific test file\npoetry run pytest tests/test_specific_module.py\n\n# Run tests with coverage\npoetry run pytest --cov=cream_api --cov-report=html\n\n# Run tests in parallel\npoetry run pytest -n auto\n\n# Run tests with verbose output\npoetry run pytest -v\n\n# Run only unit tests\npoetry run pytest tests/unit/\n\n# Run only integration tests\npoetry run pytest tests/integration/\n\n# Run tests matching pattern\npoetry run pytest -k \"test_function_name\"\n```\n\nThis test execution pattern will inform all testing procedures.\n\nAll code changes must pass all relevant tests before merging.\n\n### Test Coverage Requirements\n```yaml\n# Coverage thresholds\ncoverage:\n  global:\n    statements: 80\n    branches: 75\n    functions: 80\n    lines: 80\n\n  modules:\n    cream_api:\n      statements: 85\n      branches: 80\n      functions: 85\n      lines: 85\n\n    cream_ui:\n      statements: 80\n      branches: 75\n      functions: 80\n      lines: 80\n```\n\nThis coverage configuration will inform all test coverage requirements.\n\nAll modules must meet minimum coverage thresholds.\n\n### Test Data Management\n```python\n# Test data patterns\nimport pytest\nfrom unittest.mock import Mock, patch\n\n@pytest.fixture\ndef sample_stock_data():\n    \"\"\"Provide sample stock data for testing\"\"\"\n    return {\n        \"symbol\": \"AAPL\",\n        \"price\": 150.00,\n        \"change\": 2.50,\n        \"volume\": 1000000,\n        \"date\": \"2024-01-01\"\n    }\n\n@pytest.fixture\ndef mock_api_response():\n    \"\"\"Mock API response for testing\"\"\"\n    return {\n        \"success\": True,\n        \"data\": {\n            \"symbol\": \"AAPL\",\n            \"price\": 150.00\n        }\n    }\n\n@pytest.fixture\ndef test_database():\n    \"\"\"Provide test database connection\"\"\"\n    # Setup test database\n    db = create_test_database()\n    yield db\n    # Cleanup\n    db.close()\n```\n\nThis test data pattern will inform all test fixture implementation.\n\nAll tests must use proper fixtures and mock data.\n\n## 4. CI/CD Pipeline\n\n### GitHub Actions Workflow\n```yaml\n# .github/workflows/ci.yml\nname: CI/CD Pipeline\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main, develop]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: '3.11'\n\n    - name: Install dependencies\n      run: |\n        python -m pip install --upgrade pip\n        pip install poetry\n        poetry install\n\n    - name: Run linting\n      run: |\n        poetry run flake8 cream_api\n        poetry run black --check cream_api\n\n    - name: Run tests\n      run: |\n        poetry run pytest --cov=cream_api --cov-report=xml\n\n    - name: Upload coverage\n      uses: codecov/codecov-action@v3\n      with:\n        file: ./coverage.xml\n\n    - name: Run security scan\n      run: |\n        poetry run bandit -r cream_api/\n\n  build:\n    needs: test\n    runs-on: ubuntu-latest\n    if: github.ref == 'refs/heads/main'\n\n    steps:\n    - uses: actions/checkout@v3\n\n    - name: Build Docker image\n      run: |\n        docker build -t creampie:latest .\n\n    - name: Push to registry\n      run: |\n        echo ${{ secrets.DOCKER_PASSWORD }} | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin\n        docker tag creampie:latest ${{ secrets.DOCKER_REGISTRY }}/creampie:latest\n        docker push ${{ secrets.DOCKER_REGISTRY }}/creampie:latest\n```\n\nThis CI/CD configuration will inform all automated pipeline implementation.\n\nAll code changes must pass CI/CD pipeline before deployment.\n\n### Deployment Stages\n```yaml\n# Deployment configuration\ndeployment:\n  stages:\n    - name: development\n      branch: develop\n      environment: dev\n      auto_deploy: true\n      tests: required\n\n    - name: staging\n      branch: staging\n      environment: staging\n      auto_deploy: false\n      tests: required\n      manual_approval: true\n\n    - name: production\n      branch: main\n      environment: production\n      auto_deploy: false\n      tests: required\n      manual_approval: true\n      rollback: enabled\n```\n\nThis deployment configuration will inform all deployment stage management.\n\nAll deployments must follow proper stage progression and approval.\n\n## 5. Environment Management\n\n### Environment Configuration\n```bash\n# Environment variables structure\n# .env.development\nDATABASE_URL=postgresql://user:pass@localhost:5432/creampie_dev\nREDIS_URL=redis://localhost:6379/0\nAPI_KEY=dev_api_key\nLOG_LEVEL=DEBUG\nENVIRONMENT=development\n\n# .env.staging\nDATABASE_URL=postgresql://user:pass@staging-db:5432/creampie_staging\nREDIS_URL=redis://staging-redis:6379/0\nAPI_KEY=staging_api_key\nLOG_LEVEL=INFO\nENVIRONMENT=staging\n\n# .env.production\nDATABASE_URL=postgresql://user:pass@prod-db:5432/creampie_prod\nREDIS_URL=redis://prod-redis:6379/0\nAPI_KEY=prod_api_key\nLOG_LEVEL=WARNING\nENVIRONMENT=production\n```\n\nThis environment configuration will inform all environment variable management.\n\nAll environments must have proper configuration and secrets management.\n\n### Database Migrations\n```bash\n# Migration workflow\n# Create new migration\npoetry run alembic revision --autogenerate -m \"description of changes\"\n\n# Apply migrations\npoetry run alembic upgrade head\n\n# Rollback migration\npoetry run alembic downgrade -1\n\n# Check migration status\npoetry run alembic current\n\n# Generate migration script\npoetry run alembic revision -m \"manual migration\"\n```\n\nThis migration workflow will inform all database schema changes.\n\nAll database changes must use proper migration procedures.\n\n## 6. Monitoring and Logging\n\n### Application Monitoring\n```python\n# Monitoring configuration\nimport logging\nfrom prometheus_client import Counter, Histogram, start_http_server\n\n# Metrics\nREQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint'])\nREQUEST_DURATION = Histogram('http_request_duration_seconds', 'HTTP request duration')\n\n# Logging configuration\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('app.log'),\n        logging.StreamHandler()\n    ]\n)\n\n# Health check endpoint\n@app.get(\"/health\")\nasync def health_check():\n    return {\n        \"status\": \"healthy\",\n        \"timestamp\": datetime.utcnow(),\n        \"version\": \"1.0.0\"\n    }\n```\n\nThis monitoring configuration will inform all application monitoring implementation.\n\nAll applications must include proper monitoring and health checks.\n\n### Error Tracking\n```python\n# Error tracking configuration\nimport sentry_sdk\nfrom sentry_sdk.integrations.fastapi import FastApiIntegration\n\nsentry_sdk.init(\n    dsn=os.getenv(\"SENTRY_DSN\"),\n    integrations=[FastApiIntegration()],\n    traces_sample_rate=1.0,\n    environment=os.getenv(\"ENVIRONMENT\", \"development\")\n)\n\n# Custom error handling\n@app.exception_handler(Exception)\nasync def global_exception_handler(request: Request, exc: Exception):\n    # Log error\n    logger.error(f\"Unhandled exception: {exc}\", exc_info=True)\n\n    # Send to error tracking\n    sentry_sdk.capture_exception(exc)\n\n    return JSONResponse(\n        status_code=500,\n        content={\"detail\": \"Internal server error\"}\n    )\n```\n\nThis error tracking configuration will inform all error handling implementation.\n\nAll applications must include proper error tracking and handling.\n\n## 7. Documentation Standards\n\n### Code Documentation\n```python\n# Function documentation\ndef process_stock_data(symbol: str, data: dict) -> dict:\n    \"\"\"\n    Process raw stock data and return formatted results.\n\n    Args:\n        symbol (str): Stock symbol (e.g., 'AAPL')\n        data (dict): Raw stock data from API\n\n    Returns:\n        dict: Processed stock data with calculated fields\n\n    Raises:\n        ValueError: If symbol is invalid or data is malformed\n        ProcessingError: If data processing fails\n\n    Example:\n        >>> data = {\"price\": 150.00, \"volume\": 1000000}\n        >>> result = process_stock_data(\"AAPL\", data)\n        >>> print(result[\"formatted_price\"])\n        '$150.00'\n    \"\"\"\n    # Implementation here\n    pass\n```\n\nThis documentation pattern will inform all code documentation implementation.\n\nAll functions must include proper docstrings and examples.\n\n### API Documentation\n```python\n# FastAPI documentation\nfrom fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\n\napp = FastAPI(\n    title=\"CreamPie API\",\n    description=\"Stock data processing and analysis API\",\n    version=\"1.0.0\",\n    docs_url=\"/docs\",\n    redoc_url=\"/redoc\"\n)\n\nclass StockData(BaseModel):\n    \"\"\"Stock data model for API requests\"\"\"\n    symbol: str = Field(..., description=\"Stock symbol (e.g., AAPL)\")\n    date: str = Field(..., description=\"Date in YYYY-MM-DD format\")\n\n    class Config:\n        schema_extra = {\n            \"example\": {\n                \"symbol\": \"AAPL\",\n                \"date\": \"2024-01-01\"\n            }\n        }\n\n@app.get(\"/api/stock/{symbol}\", response_model=StockData)\nasync def get_stock_data(\n    symbol: str = Path(..., description=\"Stock symbol to retrieve\"),\n    date: str = Query(..., description=\"Date for stock data\")\n):\n    \"\"\"\n    Retrieve stock data for a given symbol and date.\n\n    - **symbol**: Stock symbol (e.g., AAPL, TSLA)\n    - **date**: Date in YYYY-MM-DD format\n\n    Returns stock price, volume, and other market data.\n    \"\"\"\n    # Implementation here\n    pass\n```\n\nThis API documentation pattern will inform all API endpoint documentation.\n\nAll API endpoints must include proper documentation and examples.\n\n## Implementation Guidelines\n\n### For AI Assistants\n1. **Follow these patterns** for all development workflow implementation\n2. **Use proper Git workflow** with meaningful commit messages\n3. **Include comprehensive testing** with proper coverage\n4. **Follow CI/CD pipeline** requirements and validation\n5. **Implement proper monitoring** and error tracking\n6. **Update documentation** with all code changes\n7. **Follow security best practices** for all deployments\n8. **Use proper environment management** for all stages\n\n### For Human Developers\n1. **Reference these patterns** when working on the project\n2. **Follow Git workflow** for all code changes\n3. **Write comprehensive tests** for new functionality\n4. **Use CI/CD pipeline** for automated validation\n5. **Monitor application health** and performance\n6. **Keep documentation updated** with changes\n7. **Follow security guidelines** for production deployments\n\n## Quality Assurance\n\n### Development Standards\n- All code changes must follow Git workflow and branching strategy\n- All commits must include proper commit messages and validation\n- All changes must pass automated testing before deployment\n- All deployments must follow proper environment promotion\n- All documentation must be updated with code changes\n\n### Testing Standards\n- Unit tests must cover all new functionality\n- Integration tests must validate component interactions\n- Test coverage must meet minimum thresholds\n- Performance tests must be included for critical paths\n- Security tests must validate input handling\n\n### Deployment Standards\n- All deployments must pass CI/CD pipeline validation\n- Environment promotion must follow proper sequence\n- Rollback procedures must be tested and documented\n- Monitoring and alerting must be configured\n- Security scanning must be performed\n\n### Documentation Standards\n- Code must be self-documenting with proper comments\n- API documentation must be comprehensive and up-to-date\n- README files must include setup and usage instructions\n- Architecture documentation must reflect current state\n- Change logs must be maintained for all releases\n\n---\n\n**AI Quality Checklist**: Before implementing development workflow changes, ensure:\n- [x] Git workflow follows branching strategy and commit standards\n- [x] Code review process includes comprehensive checklist\n- [x] Testing workflow covers all required test types\n- [x] CI/CD pipeline includes all validation steps\n- [x] Environment management follows proper configuration\n- [x] Monitoring and logging are properly configured\n- [x] Documentation standards are followed for all changes\n- [x] Security best practices are implemented throughout\n"
  },
  "cross_references": [],
  "code_generation_hints": [
    {
      "context": "general",
      "hint": "This branching strategy will inform all Git branch naming and organization.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "This commit message format will inform all Git commit message creation.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "This Git workflow will inform all version control operations.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "This PR template will inform all pull request creation and review.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "This review checklist will inform all code review processes.",
      "validation": ""
    },
    {
      "context": "testing",
      "hint": "This test execution pattern will inform all testing procedures.",
      "validation": ""
    },
    {
      "context": "testing",
      "hint": "This coverage configuration will inform all test coverage requirements.",
      "validation": ""
    },
    {
      "context": "testing",
      "hint": "This test data pattern will inform all test fixture implementation.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "This CI/CD configuration will inform all automated pipeline implementation.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "This deployment configuration will inform all deployment stage management.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "This environment configuration will inform all environment variable management.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "This migration workflow will inform all database schema changes.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "This monitoring configuration will inform all application monitoring implementation.",
      "validation": ""
    },
    {
      "context": "error handling",
      "hint": "This error tracking configuration will inform all error handling implementation.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "This documentation pattern will inform all code documentation implementation.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "This API documentation pattern will inform all API endpoint documentation.",
      "validation": ""
    }
  ],
  "validation_rules": [
    "name: production\n      branch: main\n      environment: production\n      auto_deploy: false\n      tests: required\n      manual_approval: true\n      rollback: enabled\n```",
    "All branches must follow this naming convention and purpose",
    "Integration tests must validate component interactions",
    "Change logs must be maintained for all releases",
    "All code changes must follow Git workflow and branching strategy",
    "All applications must include proper error tracking and handling",
    "API documentation must be comprehensive and up-to-date",
    "All code changes must pass all relevant tests before merging",
    "All functions must include proper docstrings and examples",
    "All changes must pass automated testing before deployment",
    "Code must be self-documenting with proper comments",
    "All deployments must follow proper environment promotion",
    "Security scanning must be performed",
    "name: development\n      branch: develop\n      environment: dev\n      auto_deploy: true\n      tests: required",
    "All Git operations must follow this workflow sequence",
    "All documentation must be updated with code changes",
    "[x] Testing workflow covers all required test types",
    "Rollback procedures must be tested and documented",
    "All API endpoints must include proper documentation and examples",
    "Monitoring and alerting must be configured",
    "All applications must include proper monitoring and health checks",
    "All modules must meet minimum coverage thresholds",
    "Environment promotion must follow proper sequence",
    "All code reviews must follow this checklist for comprehensive evaluation",
    "All deployments must pass CI/CD pipeline validation",
    "Test coverage must meet minimum thresholds",
    "README files must include setup and usage instructions",
    "Unit tests must cover all new functionality",
    "Architecture documentation must reflect current state",
    "All tests must use proper fixtures and mock data",
    "Security tests must validate input handling",
    "All pull requests must include proper description and checklist completion",
    "All code changes must pass CI/CD pipeline before deployment",
    "All environments must have proper configuration and secrets management",
    "All database changes must use proper migration procedures",
    "All commits must follow this format with proper type and description",
    "Performance tests must be included for critical paths",
    "All deployments must follow proper stage progression and approval",
    "name: staging\n      branch: staging\n      environment: staging\n      auto_deploy: false\n      tests: required\n      manual_approval: true",
    "All commits must include proper commit messages and validation"
  ],
  "optimization": {
    "version": "1.0",
    "optimized_at": "2025-06-18T19:19:47.760641",
    "improvements": [
      "fixed_file_references",
      "extracted_ai_metadata",
      "structured_cross_references",
      "extracted_code_hints",
      "structured_validation_rules"
    ],
    "literal_strings_cleaned": true,
    "cleaned_at": "2025-06-18T19:30:00.000000"
  }
}