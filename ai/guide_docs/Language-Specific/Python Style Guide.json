{
  "ai_metadata": {
    "purpose": "",
    "last_updated": "",
    "template_version": "2.1",
    "ai_tool_compatibility": "",
    "ai_processing_level": "High",
    "required_context": "Python language features, project architecture, existing codebase",
    "validation_required": "Yes",
    "code_generation": "Supported",
    "cross_references": [
      "../Core%20Principles.json",
      "../project_context/Common%20Patterns.json",
      "../project_context/Architecture%20Overview.json",
      "FastAPI%20Development%20Guide.json",
      "Python%20Testing%20Guide.json"
    ],
    "maintenance": ""
  },
  "file_info": {
    "file_path": "guide_docs/Language-Specific/Python Style Guide.md",
    "original_format": "markdown",
    "converted_at": "2025-06-18T19:14:30.253188",
    "file_size": 22659,
    "line_count": 620,
    "optimized_at": "2025-06-18T19:19:47.743098",
    "optimization_version": "1.0"
  },
  "content": {
    "sections": [
      {
        "level": 1,
        "title": "Python Style Guide",
        "content": "> This guide provides comprehensive Python coding standards and best practices. Use these patterns to ensure consistent, readable, and maintainable Python code.",
        "subsections": []
      },
      {
        "level": 2,
        "title": "AI Metadata",
        "content": "**Template Version:** 2.1\n**AI Processing Level:** High\n**Required Context:** Python language features, project architecture, existing codebase\n**Validation Required:** Yes\n**Code Generation:** Supported\n\n**Dependencies:**\n- `../Core%20Principles.json.replace(\".json\", \".json\")` - Decision-making frameworks\n- `../project_context/Common%20Patterns.json.replace(\".json\", \".json\")` - Project patterns\n- `../project_context/Architecture%20Overview.json.replace(\".json\", \".json\")` - System architecture\n- `FastAPI%20Development%20Guide.json.replace(\".json\", \".json\")` - API development patterns\n- `Python%20Testing%20Guide.json.replace(\".json\", \".json\")` - Testing patterns\n\n**Validation Rules:**\n- All code must follow PEP 8 style guidelines\n- Type hints must be used for all function parameters and return values\n- Docstrings must be included for all modules, classes, and functions\n- Import organization must follow established patterns\n- Error handling must follow project conventions",
        "subsections": []
      },
      {
        "level": 2,
        "title": "Overview",
        "content": "**Document Purpose:** Python coding standards and best practices for the CreamPie project\n**Scope:** All Python code, including backend APIs, data processing, and utilities\n**Target Users:** AI assistants and developers writing Python code\n**Last Updated:** Current\n\n**AI Context:** This guide provides the foundational Python coding standards that must be followed for all Python code in the project. It ensures consistency, readability, and maintainability across the codebase.",
        "subsections": []
      },
      {
        "level": 2,
        "title": "1. Code Style and Best Practices",
        "content": "",
        "subsections": []
      },
      {
        "level": 3,
        "title": "General Guidelines",
        "content": "- Follow PEP 8 style guide\n- Use type hints for all function parameters and return values\n  - Use `|` for union types in Python 3.10+\n  - Use built-in types (`dict`, `list`, `set`, etc.) instead of `typing.Dict`, `typing.List`, etc.\n  - Only import from `typing` for types that don't have built-in equivalents\n- Use docstrings for all modules, classes, and functions\n- Use meaningful variable and function names\n- Keep functions small and focused\n- Do not use magic numbers that are not 1, 2, -1 or 0\n\nThese guidelines will inform all Python code generation and review activities.\n\nAll generated code must follow these guidelines without exception.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Import Organization",
        "content": "- Group imports in the following order:\n  1. Standard library imports\n  2. Third-party imports\n  3. Local application imports\n- Separate imports with a blank line between groups\n- Remove unused imports to keep the codebase clean\n- Use direct access to settings when appropriate instead of creating local variables\n- Place `__all__` at the top of a module after imports\n\nThis organization will inform import structure for all Python modules.\n\nImport organization must follow this exact order and grouping.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Data Structures and Operations",
        "content": "- Use dataclasses for data containers\n- Use enums for constants\n- Use list comprehensions for simple transformations\n- Use generator expressions for large datasets\n- Use sets for membership testing\n- Use dict.get() for safe access\n- Use collections.deque for queues\n\nThese patterns will inform data structure selection and usage throughout the codebase.\n\nData structure usage must be appropriate for the specific use case and performance requirements.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "File and Path Handling",
        "content": "- Use os.path for file paths\n  - os.path is preferred over pathlib because it works as strings instead of needing to be coerced\n- Use the standard `datetime` library for date/time operations\n  - Use `datetime.now(datetime.UTC)` instead of `datetime.utcnow()`, which is deprecated\n  - This provides better timezone awareness and is the preferred method in modern Python\n\nThese patterns will inform file and path handling implementation throughout the project.\n\nFile and path handling must use the specified libraries and methods.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "AI Script Development Patterns",
        "content": "- **Report Generation**: Always generate both human-readable (Markdown) and machine-readable (JSON) reports\n  - Use consistent AI metadata and cross-references in all generated reports\n  - Include timestamps, success/failure metrics, and actionable recommendations\n- **Error Handling**: Use comprehensive try/except blocks with detailed error messages\n  - Collect errors in lists for batch reporting\n  - Provide both console output and structured file output\n- **Link Validation**: Implement intelligent false-positive detection for URL-encoded and relative links\n  - Check for directory references, script files, and configuration files\n  - Handle URL-encoded links with proper decoding\n- **Function Complexity**: Break complex functions into smaller, focused helper methods\n  - Prefer single return points for complex validation functions\n  - Use descriptive method names that clearly indicate their purpose\n- **Unused Variables**: Use underscore prefix for unused loop variables (e.g., `_dirs`, `_link_text`)\n  - This satisfies linting requirements while maintaining code clarity\n- **String Formatting**: Use f-strings for dynamic content, break long strings for readability\n  - Extract complex expressions into variables to avoid line length violations\n  - Use multi-line string concatenation for complex report generation\n- **Performance Considerations**: Optimize for readability over performance in non-critical paths\n  - AI scripts are typically run infrequently, so maintainability is more important than speed\n  - Use clear, explicit logic even if it means multiple checks\n\nThese patterns will inform AI script development and maintenance throughout the project.\n\nAI scripts must follow these patterns for consistency, maintainability, and AI tool consumption.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Resource Management",
        "content": "- Split context manager creation into separate statements when the constructor has many parameters or is difficult to read\n- Simple context managers with few or no parameters can remain inline\n- Factory functions (like `AsyncSessionLocal()`) are simple enough to use inline\n\n```python",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Good - complex constructor with many parameters",
        "content": "session = aiohttp.ClientSession(\n    timeout=timeout,\n    headers=headers,\n    skip_auto_headers=['Accept-Encoding']\n)\nasync with session:\n    # use session",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Avoid - complex constructor inline makes it hard to read",
        "content": "async with aiohttp.ClientSession(\n    timeout=timeout,\n    headers=headers,\n    skip_auto_headers=['Accept-Encoding']\n) as session:\n    # use session",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Good - simple constructor can remain inline",
        "content": "async with ClientSession() as session:\n    # use session",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Good - factory functions can remain inline",
        "content": "async with AsyncSessionLocal() as session:\n    # use session",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Good - simple context managers with few parameters",
        "content": "with open('file.txt', 'r') as f:\n    # use file\n```\n\nThese patterns will inform context manager usage and resource management throughout the codebase.\n\nContext manager usage must follow these readability guidelines.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Configuration Management",
        "content": "- Load configuration once at module level to avoid redundant calls\n- Use module-level variables for configuration that doesn't change during runtime\n- Avoid calling configuration functions multiple times in the same module\n\n```python",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Good - load once at module level",
        "content": "config = get_stock_data_config()\n\ndef some_function():\n    retriever = StockDataRetriever(config=config)  # Use module-level config",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Avoid - loading config multiple times",
        "content": "def some_function():\n    config = get_stock_data_config()  # Redundant call\n    retriever = StockDataRetriever(config=config)\n```\n\nThis pattern will inform configuration loading and usage throughout the project.\n\nConfiguration must be loaded once at module level and reused, not loaded multiple times.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Constants and Magic Numbers",
        "content": "- Define constants at module level for configuration values\n- Use descriptive names for time intervals and other magic numbers\n- Group related constants together\n\n```python",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Good - named constants",
        "content": "RETRIEVAL_INTERVAL_SECONDS = 5 * 60\nPROCESSING_INTERVAL_SECONDS = 10 * 60",
        "subsections": []
      },
      {
        "level": 1,
        "title": "Avoid - magic numbers in code",
        "content": "await asyncio.sleep(5 * 60)  # What does 300 seconds mean?\n```\n\nThis pattern will inform constant definition and usage throughout the codebase.\n\nMagic numbers must be replaced with named constants unless they are 1, 2, -1, or 0.",
        "subsections": []
      },
      {
        "level": 2,
        "title": "2. Project Structure and Organization",
        "content": "",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Directory Structure",
        "content": "```\ncream_api/\n├── __init__.py\n├── migrations/\n│   ├── __init__.py      # Required for proper package structure\n│   ├── env.py           # Import all models here\n│   └── versions/        # Migration files\n├── models/\n│   └── __init__.py\n└── ...\n```\n\nThis structure will inform package organization and module placement throughout the project.\n\nDirectory structure must follow this organization for consistency and maintainability.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Package Organization",
        "content": "- Keep related functionality in dedicated modules\n- Use `__init__.py` files to mark directories as Python packages\n- Separate configuration, database, and application logic into different modules\n- Never have circular imports\n- Use absolute imports for clarity\n\nThis organization will inform module structure and import patterns throughout the project.\n\nPackage organization must avoid circular imports and maintain clear separation of concerns.",
        "subsections": []
      },
      {
        "level": 2,
        "title": "3. Error Handling and Security",
        "content": "",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Error Handling",
        "content": "- Use custom exceptions for domain-specific errors\n- Use context managers for cleanup\n- Use try/except blocks for expected errors\n- Use raise from for exception chaining\n- Use logging for error tracking\n- Maintain error handling at the appropriate level\n- Consider implementing more specific exception types\n- Validate input data using Pydantic models\n- Use type assertions when necessary for type safety\n\nThese patterns will inform error handling implementation throughout the codebase.\n\nError handling must be comprehensive and follow established patterns.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Security",
        "content": "- Never hardcode sensitive information\n- Use environment variables for secrets\n- Use secrets module for random values\n- Use hashlib for hashing\n- Use ssl for secure connections\n- Use hmac for message authentication\n- Use cryptography for encryption\n- Implement proper CORS configuration\n- Validate all input data\n- Use secure database connection strings\n\nThese security practices will inform all code generation and review activities.\n\nSecurity practices must be followed without exception for all sensitive operations.",
        "subsections": []
      },
      {
        "level": 2,
        "title": "4. Refactoring Guidelines",
        "content": "",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Single Responsibility Principle",
        "content": "- Classes should have a single, clear purpose\n- Remove functionality that doesn't align with the class's core responsibility\n- Rename classes to better reflect their focused responsibility\n\nThis principle will inform class design and refactoring decisions throughout the project.\n\nClasses must have a single, clear responsibility and be appropriately named.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Resource Management",
        "content": "- Handle directory creation and management at a higher level\n- Data processing classes should not be responsible for ensuring directory existence\n- This separation of concerns makes the code more maintainable and testable\n\nThis pattern will inform resource management and separation of concerns.\n\nResource management must be handled at appropriate levels with clear separation of concerns.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "File Processing",
        "content": "- Delegate parsing responsibility to dedicated parser classes\n- Keep file movement operations simple and focused\n- Consider moving directory structure management to a configuration/setup module\n\nThis pattern will inform file processing architecture and responsibility separation.\n\nFile processing must follow established patterns with clear responsibility separation.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Future Considerations",
        "content": "- Consider implementing dedicated services for specific functionalities\n- Move configuration and setup logic to appropriate modules\n- Enhance error handling with specific exception types and logging\n- Refactor functions with \"and\" in their name into separate functions\n  - Example: `process_and_validate_data()` should be split into `process_data()` and `validate_data()`\n\nThese considerations will inform future refactoring and improvement decisions.\n\nFuture improvements must maintain code quality and follow established patterns.",
        "subsections": []
      },
      {
        "level": 2,
        "title": "5. Type Hints and Annotations",
        "content": "",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Function Type Hints",
        "content": "```python\nfrom typing import Optional, List, Dict, Any\nfrom datetime import datetime\n\ndef process_stock_data(\n    symbol: str,\n    start_date: datetime,\n    end_date: Optional[datetime] = None\n) -> List[Dict[str, Any]]:\n    \"\"\"Process stock data for a given symbol and date range.\"\"\"\n    pass\n\nasync def fetch_stock_data(\n    symbol: str,\n    session: AsyncSession\n) -> Optional[StockData]:\n    \"\"\"Fetch stock data from database.\"\"\"\n    pass\n```\n\nThese patterns will inform type hint usage throughout the codebase.\n\nAll functions must include proper type hints for parameters and return values.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Class Type Hints",
        "content": "```python\nfrom dataclasses import dataclass\nfrom typing import Optional\n\n@dataclass\nclass StockData:\n    symbol: str\n    date: datetime\n    price: int\n    volume: Optional[int] = None\n\nclass StockDataProcessor:\n    def __init__(self, config: Dict[str, Any]) -> None:\n        self.config = config\n\n    async def process(self, data: List[StockData]) -> bool:\n        \"\"\"Process a list of stock data.\"\"\"\n        pass\n```\n\nThese patterns will inform class type hint usage and dataclass implementation.\n\nAll classes must include proper type hints and use dataclasses where appropriate.",
        "subsections": []
      },
      {
        "level": 2,
        "title": "6. Async/Await Patterns",
        "content": "",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Async Function Structure",
        "content": "```python\nimport asyncio\nimport aiohttp\nfrom typing import List, Dict, Any\n\nasync def fetch_multiple_stocks(\n    symbols: List[str],\n    session: aiohttp.ClientSession\n) -> Dict[str, Any]:\n    \"\"\"Fetch data for multiple stock symbols concurrently.\"\"\"\n    tasks = [\n        fetch_single_stock(symbol, session)\n        for symbol in symbols\n    ]\n    results = await asyncio.gather(*tasks, return_exceptions=True)\n\n    return {\n        symbol: result\n        for symbol, result in zip(symbols, results)\n        if not isinstance(result, Exception)\n    }\n\nasync def fetch_single_stock(\n    symbol: str,\n    session: aiohttp.ClientSession\n) -> Dict[str, Any]:\n    \"\"\"Fetch data for a single stock symbol.\"\"\"\n    try:\n        async with session.get(f\"/api/stocks/{symbol}\") as response:\n            if response.status == 200:\n                return await response.json()\n            else:\n                raise ValueError(f\"Failed to fetch {symbol}\")\n    except Exception as e:\n        logger.error(f\"Error fetching {symbol}: {e}\")\n        raise\n```\n\nThese patterns will inform async/await implementation throughout the codebase.\n\nAsync functions must include proper error handling and follow established patterns.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Database Operations",
        "content": "```python\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom typing import Optional\n\nasync def get_stock_data(\n    symbol: str,\n    session: AsyncSession\n) -> Optional[StockData]:\n    \"\"\"Get stock data from database.\"\"\"\n    try:\n        result = await session.execute(\n            select(StockData).where(StockData.symbol == symbol)\n        )\n        return result.scalar_one_or_none()\n    except Exception as e:\n        logger.error(f\"Database error for {symbol}: {e}\")\n        raise\n\nasync def save_stock_data(\n    data: StockData,\n    session: AsyncSession\n) -> bool:\n    \"\"\"Save stock data to database.\"\"\"\n    try:\n        session.add(data)\n        await session.commit()\n        return True\n    except Exception as e:\n        await session.rollback()\n        logger.error(f\"Failed to save stock data: {e}\")\n        return False\n```\n\nThese patterns will inform database operation implementation throughout the project.\n\nDatabase operations must include proper error handling, transaction management, and logging.",
        "subsections": []
      },
      {
        "level": 2,
        "title": "7. Testing Patterns",
        "content": "",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Unit Test Structure",
        "content": "```python\nimport pytest\nfrom unittest.mock import AsyncMock, patch\nfrom typing import List\n\nclass TestStockDataProcessor:\n    \"\"\"Test cases for StockDataProcessor.\"\"\"\n\n    @pytest.fixture\n    def processor(self) -> StockDataProcessor:\n        \"\"\"Create processor instance for testing.\"\"\"\n        config = {\"test\": True, \"timeout\": 30}\n        return StockDataProcessor(config)\n\n    @pytest.fixture\n    def sample_data(self) -> List[StockData]:\n        \"\"\"Create sample stock data for testing.\"\"\"\n        return [\n            StockData(symbol=\"AAPL\", date=datetime.now(), price=15000),\n            StockData(symbol=\"GOOGL\", date=datetime.now(), price=25000)\n        ]\n\n    @pytest.mark.asyncio\n    async def test_process_data_success(\n        self,\n        processor: StockDataProcessor,\n        sample_data: List[StockData]\n    ) -> None:\n        \"\"\"Test successful data processing.\"\"\"\n        with patch.object(processor, '_validate_data') as mock_validate:\n            mock_validate.return_value = True\n\n            result = await processor.process_data(sample_data)\n\n            assert result is True\n            mock_validate.assert_called_once_with(sample_data)\n\n    @pytest.mark.asyncio\n    async def test_process_data_validation_failure(\n        self,\n        processor: StockDataProcessor,\n        sample_data: List[StockData]\n    ) -> None:\n        \"\"\"Test data processing with validation failure.\"\"\"\n        with patch.object(processor, '_validate_data') as mock_validate:\n            mock_validate.return_value = False\n\n            result = await processor.process_data(sample_data)\n\n            assert result is False\n```\n\nThese patterns will inform unit test structure and implementation throughout the project.\n\nUnit tests must include proper fixtures, async testing, and comprehensive error case coverage.",
        "subsections": []
      },
      {
        "level": 2,
        "title": "8. Documentation Patterns",
        "content": "",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Module Docstrings",
        "content": "```python\n\"\"\"\nStock Data Processing Module\n\nThis module provides functionality for retrieving, processing, and storing\nstock market data from various sources. It includes data validation,\ntransformation, and database operations.\n\nKey Components:\n- StockDataRetriever: Handles data retrieval from external APIs\n- StockDataProcessor: Processes and validates stock data\n- StockDataLoader: Manages database operations for stock data\n\nDependencies:\n- aiohttp: For async HTTP requests\n- sqlalchemy: For database operations\n- pydantic: For data validation\n\nExample Usage:\n    processor = StockDataProcessor(config)\n    data = await processor.process_symbol(\"AAPL\")\n\"\"\"\n\nimport asyncio\nimport logging\nfrom typing import List, Dict, Any\n```\n\nThese patterns will inform module documentation throughout the project.\n\nAll modules must include comprehensive docstrings with purpose, components, and usage examples.",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Function Docstrings",
        "content": "```python\nasync def process_stock_data(\n    symbol: str,\n    start_date: datetime,\n    end_date: Optional[datetime] = None\n) -> List[Dict[str, Any]]:\n    \"\"\"\n    Process stock data for a given symbol and date range.\n\n    Args:\n        symbol: Stock symbol (e.g., 'AAPL', 'GOOGL')\n        start_date: Start date for data retrieval\n        end_date: End date for data retrieval (defaults to current date)\n\n    Returns:\n        List of processed stock data dictionaries\n\n    Raises:\n        ValueError: If symbol is invalid or date range is invalid\n        ConnectionError: If unable to connect to data source\n\n    Example:\n        data = await process_stock_data(\"AAPL\", datetime(2024, 1, 1))\n    \"\"\"\n    pass\n```\n\nThese patterns will inform function documentation throughout the project.\n\nAll functions must include comprehensive docstrings with parameters, return values, exceptions, and examples.",
        "subsections": []
      },
      {
        "level": 2,
        "title": "Implementation Guidelines",
        "content": "",
        "subsections": []
      },
      {
        "level": 3,
        "title": "For AI Assistants",
        "content": "1. **Follow this guide** for all Python code generation\n2. **Use type hints** for all functions and classes\n3. **Include docstrings** for all modules, classes, and functions\n4. **Follow PEP 8** for code formatting and style\n5. **Apply error handling** patterns consistently\n6. **Use async/await** for I/O operations\n7. **Validate inputs** using Pydantic models\n8. **Write tests** for all new functionality",
        "subsections": []
      },
      {
        "level": 3,
        "title": "For Human Developers",
        "content": "1. **Reference this guide** when writing Python code\n2. **Use type hints** to improve code clarity and IDE support\n3. **Write comprehensive docstrings** for maintainability\n4. **Follow established patterns** for consistency\n5. **Test your code** thoroughly\n6. **Review code** against these standards\n7. **Suggest improvements** when better patterns are found",
        "subsections": []
      },
      {
        "level": 2,
        "title": "Quality Assurance",
        "content": "",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Code Quality Standards",
        "content": "- All code must follow PEP 8 style guidelines\n- Type hints must be used consistently\n- Docstrings must be comprehensive and accurate\n- Error handling must be appropriate and comprehensive\n- Security practices must be followed without exception",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Testing Requirements",
        "content": "- All new functionality must include unit tests\n- Tests must cover both success and failure cases\n- Async functions must be tested with proper async testing\n- Mocking must be used appropriately for external dependencies",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Documentation Standards",
        "content": "- All modules must include comprehensive docstrings\n- Function docstrings must include parameters, return values, and examples\n- Complex logic must be documented with comments\n- Architecture decisions must be documented",
        "subsections": []
      },
      {
        "level": 3,
        "title": "Performance Considerations",
        "content": "- Use async/await for I/O operations\n- Use appropriate data structures for performance\n- Avoid unnecessary object creation\n- Profile code when performance issues arise\n\n---\n\n**AI Quality Checklist**: Before generating Python code, ensure:\n- [x] Code follows PEP 8 style guidelines\n- [x] Type hints are used for all functions and classes\n- [x] Docstrings are comprehensive and accurate\n- [x] Error handling follows established patterns\n- [x] Security practices are implemented\n- [x] Async/await is used for I/O operations\n- [x] Input validation is implemented\n- [x] Tests are included for new functionality",
        "subsections": []
      },
      {
        "level": 3,
        "title": "AI Script Optimization Lessons",
        "content": "**Lesson Learned**: AI script development requires specific optimization patterns:\n\n- **Linter Compliance**: Break complex functions to avoid PLR0912 (too many branches) and PLR0911 (too many returns)\n  - Use boolean variables for single return points in complex validation functions\n  - Split large functions into focused helper methods with clear responsibilities\n- **Error Handling**: Use specific exception types instead of bare `except:`\n  - Replace `except:` with `except Exception:` or specific exception types\n  - Provide detailed error messages for debugging\n- **Function Complexity**: Keep functions focused and maintainable\n  - Maximum 12 branches per function (PLR0912)\n  - Maximum 6 return statements per function (PLR0911)\n  - Use descriptive method names that clearly indicate purpose\n- **Performance vs Readability**: Prioritize readability for AI scripts\n  - AI scripts run infrequently, so maintainability is more important than speed\n  - Use clear, explicit logic even if it means multiple checks\n  - Prefer explicit boolean variables over complex conditional returns\n- **File Processing**: Handle different file formats and structures intelligently\n  - Skip files with different structures (output files, reports)\n  - Handle URL-encoded paths and file references\n  - Implement smart false-positive detection for validation\n- **Code Organization**: Structure for maintainability and clarity\n  - Group related functionality in helper methods\n  - Use consistent naming patterns for similar operations\n  - Separate validation logic from processing logic",
        "subsections": []
      },
      {
        "level": 3,
        "title": "JSON Processing Patterns",
        "language": "python",
        "code": "# Good - load once at module level\nconfig = get_stock_data_config()\n\ndef some_function():\n    retriever = StockDataRetriever(config=config)  # Use module-level config\n\n# Avoid - loading config multiple times\ndef some_function():\n    config = get_stock_data_config()  # Redundant call\n    retriever = StockDataRetriever(config=config)"
      },
      {
        "language": "python",
        "code": "# Good - named constants\nRETRIEVAL_INTERVAL_SECONDS = 5 * 60\nPROCESSING_INTERVAL_SECONDS = 10 * 60\n\n# Avoid - magic numbers in code\nawait asyncio.sleep(5 * 60)  # What does 300 seconds mean?"
      },
      {
        "language": "text",
        "code": "cream_api/\n├── __init__.py\n├── migrations/\n│   ├── __init__.py      # Required for proper package structure\n│   ├── env.py           # Import all models here\n│   └── versions/        # Migration files\n├── models/\n│   └── __init__.py\n└── ..."
      },
      {
        "language": "python",
        "code": "from typing import Optional, List, Dict, Any\nfrom datetime import datetime\n\ndef process_stock_data(\n    symbol: str,\n    start_date: datetime,\n    end_date: Optional[datetime] = None\n) -> List[Dict[str, Any]]:\n    \"\"\"Process stock data for a given symbol and date range.\"\"\"\n    pass\n\nasync def fetch_stock_data(\n    symbol: str,\n    session: AsyncSession\n) -> Optional[StockData]:\n    \"\"\"Fetch stock data from database.\"\"\"\n    pass"
      },
      {
        "language": "python",
        "code": "from dataclasses import dataclass\nfrom typing import Optional\n\n@dataclass\nclass StockData:\n    symbol: str\n    date: datetime\n    price: int\n    volume: Optional[int] = None\n\nclass StockDataProcessor:\n    def __init__(self, config: Dict[str, Any]) -> None:\n        self.config = config\n\n    async def process(self, data: List[StockData]) -> bool:\n        \"\"\"Process a list of stock data.\"\"\"\n        pass"
      },
      {
        "language": "python",
        "code": "import asyncio\nimport aiohttp\nfrom typing import List, Dict, Any\n\nasync def fetch_multiple_stocks(\n    symbols: List[str],\n    session: aiohttp.ClientSession\n) -> Dict[str, Any]:\n    \"\"\"Fetch data for multiple stock symbols concurrently.\"\"\"\n    tasks = [\n        fetch_single_stock(symbol, session)\n        for symbol in symbols\n    ]\n    results = await asyncio.gather(*tasks, return_exceptions=True)\n\n    return {\n        symbol: result\n        for symbol, result in zip(symbols, results)\n        if not isinstance(result, Exception)\n    }\n\nasync def fetch_single_stock(\n    symbol: str,\n    session: aiohttp.ClientSession\n) -> Dict[str, Any]:\n    \"\"\"Fetch data for a single stock symbol.\"\"\"\n    try:\n        async with session.get(f\"/api/stocks/{symbol}\") as response:\n            if response.status == 200:\n                return await response.json()\n            else:\n                raise ValueError(f\"Failed to fetch {symbol}\")\n    except Exception as e:\n        logger.error(f\"Error fetching {symbol}: {e}\")\n        raise"
      },
      {
        "language": "python",
        "code": "from sqlalchemy.ext.asyncio import AsyncSession\nfrom typing import Optional\n\nasync def get_stock_data(\n    symbol: str,\n    session: AsyncSession\n) -> Optional[StockData]:\n    \"\"\"Get stock data from database.\"\"\"\n    try:\n        result = await session.execute(\n            select(StockData).where(StockData.symbol == symbol)\n        )\n        return result.scalar_one_or_none()\n    except Exception as e:\n        logger.error(f\"Database error for {symbol}: {e}\")\n        raise\n\nasync def save_stock_data(\n    data: StockData,\n    session: AsyncSession\n) -> bool:\n    \"\"\"Save stock data to database.\"\"\"\n    try:\n        session.add(data)\n        await session.commit()\n        return True\n    except Exception as e:\n        await session.rollback()\n        logger.error(f\"Failed to save stock data: {e}\")\n        return False"
      },
      {
        "language": "python",
        "code": "import pytest\nfrom unittest.mock import AsyncMock, patch\nfrom typing import List\n\nclass TestStockDataProcessor:\n    \"\"\"Test cases for StockDataProcessor.\"\"\"\n\n    @pytest.fixture\n    def processor(self) -> StockDataProcessor:\n        \"\"\"Create processor instance for testing.\"\"\"\n        config = {\"test\": True, \"timeout\": 30}\n        return StockDataProcessor(config)\n\n    @pytest.fixture\n    def sample_data(self) -> List[StockData]:\n        \"\"\"Create sample stock data for testing.\"\"\"\n        return [\n            StockData(symbol=\"AAPL\", date=datetime.now(), price=15000),\n            StockData(symbol=\"GOOGL\", date=datetime.now(), price=25000)\n        ]\n\n    @pytest.mark.asyncio\n    async def test_process_data_success(\n        self,\n        processor: StockDataProcessor,\n        sample_data: List[StockData]\n    ) -> None:\n        \"\"\"Test successful data processing.\"\"\"\n        with patch.object(processor, '_validate_data') as mock_validate:\n            mock_validate.return_value = True\n\n            result = await processor.process_data(sample_data)\n\n            assert result is True\n            mock_validate.assert_called_once_with(sample_data)\n\n    @pytest.mark.asyncio\n    async def test_process_data_validation_failure(\n        self,\n        processor: StockDataProcessor,\n        sample_data: List[StockData]\n    ) -> None:\n        \"\"\"Test data processing with validation failure.\"\"\"\n        with patch.object(processor, '_validate_data') as mock_validate:\n            mock_validate.return_value = False\n\n            result = await processor.process_data(sample_data)\n\n            assert result is False"
      },
      {
        "language": "python",
        "code": "\"\"\"\nStock Data Processing Module\n\nThis module provides functionality for retrieving, processing, and storing\nstock market data from various sources. It includes data validation,\ntransformation, and database operations.\n\nKey Components:\n- StockDataRetriever: Handles data retrieval from external APIs\n- StockDataProcessor: Processes and validates stock data\n- StockDataLoader: Manages database operations for stock data\n\nDependencies:\n- aiohttp: For async HTTP requests\n- sqlalchemy: For database operations\n- pydantic: For data validation\n\nExample Usage:\n    processor = StockDataProcessor(config)\n    data = await processor.process_symbol(\"AAPL\")\n\"\"\"\n\nimport asyncio\nimport logging\nfrom typing import List, Dict, Any"
      },
      {
        "language": "python",
        "code": "async def process_stock_data(\n    symbol: str,\n    start_date: datetime,\n    end_date: Optional[datetime] = None\n) -> List[Dict[str, Any]]:\n    \"\"\"\n    Process stock data for a given symbol and date range.\n\n    Args:\n        symbol: Stock symbol (e.g., 'AAPL', 'GOOGL')\n        start_date: Start date for data retrieval\n        end_date: End date for data retrieval (defaults to current date)\n\n    Returns:\n        List of processed stock data dictionaries\n\n    Raises:\n        ValueError: If symbol is invalid or date range is invalid\n        ConnectionError: If unable to connect to data source\n\n    Example:\n        data = await process_stock_data(\"AAPL\", datetime(2024, 1, 1))\n    \"\"\"\n    pass"
      }
    ],
    "links": [
      {
        "type": "code_reference",
        "text": "../Core%20Principles.md"
      },
      {
        "type": "code_reference",
        "text": "../project_context/Common%20Patterns.md"
      },
      {
        "type": "code_reference",
        "text": "../project_context/Architecture%20Overview.md"
      },
      {
        "type": "code_reference",
        "text": "FastAPI%20Development%20Guide.md"
      },
      {
        "type": "code_reference",
        "text": "Python%20Testing%20Guide.md"
      },
      {
        "type": "code_reference",
        "text": "typing.Dict"
      },
      {
        "type": "code_reference",
        "text": "typing.List"
      },
      {
        "type": "code_reference",
        "text": "datetime.now(datetime.UTC)"
      },
      {
        "type": "code_reference",
        "text": "datetime.utcnow()"
      },
      {
        "type": "code_reference",
        "text": "python\n# Good - complex constructor with many parameters\nsession = aiohttp.ClientSession(\n    timeout=timeout,\n    headers=headers,\n    skip_auto_headers=['Accept-Encoding']\n)\nasync with session:\n    # use session\n\n# Avoid - complex constructor inline makes it hard to read\nasync with aiohttp.ClientSession(\n    timeout=timeout,\n    headers=headers,\n    skip_auto_headers=['Accept-Encoding']\n) as session:\n    # use session\n\n# Good - simple constructor can remain inline\nasync with ClientSession() as session:\n    # use session\n\n# Good - factory functions can remain inline\nasync with AsyncSessionLocal() as session:\n    # use session\n\n# Good - simple context managers with few parameters\nwith open('file.txt', 'r') as f:\n    # use file\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThese patterns will inform context manager usage and resource management throughout the codebase.\n\nContext manager usage must follow these readability guidelines.\n\n### Configuration Management\n- Load configuration once at module level to avoid redundant calls\n- Use module-level variables for configuration that doesn't change during runtime\n- Avoid calling configuration functions multiple times in the same module\n\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThis pattern will inform configuration loading and usage throughout the project.\n\nConfiguration must be loaded once at module level and reused, not loaded multiple times.\n\n### Constants and Magic Numbers\n- Define constants at module level for configuration values\n- Use descriptive names for time intervals and other magic numbers\n- Group related constants together\n\n"
      },
      {
        "type": "code_reference",
        "text": "python\n# Good - named constants\nRETRIEVAL_INTERVAL_SECONDS = 5 * 60\nPROCESSING_INTERVAL_SECONDS = 10 * 60\n\n# Avoid - magic numbers in code\nawait asyncio.sleep(5 * 60)  # What does 300 seconds mean?\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThis pattern will inform constant definition and usage throughout the codebase.\n\nMagic numbers must be replaced with named constants unless they are 1, 2, -1, or 0.\n\n## 2. Project Structure and Organization\n\n### Directory Structure\n"
      },
      {
        "type": "code_reference",
        "text": "\ncream_api/\n├── __init__.py\n├── migrations/\n│   ├── __init__.py      # Required for proper package structure\n│   ├── env.py           # Import all models here\n│   └── versions/        # Migration files\n├── models/\n│   └── __init__.py\n└── ...\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThis structure will inform package organization and module placement throughout the project.\n\nDirectory structure must follow this organization for consistency and maintainability.\n\n### Package Organization\n- Keep related functionality in dedicated modules\n- Use "
      },
      {
        "type": "code_reference",
        "text": " files to mark directories as Python packages\n- Separate configuration, database, and application logic into different modules\n- Never have circular imports\n- Use absolute imports for clarity\n\nThis organization will inform module structure and import patterns throughout the project.\n\nPackage organization must avoid circular imports and maintain clear separation of concerns.\n\n## 3. Error Handling and Security\n\n### Error Handling\n- Use custom exceptions for domain-specific errors\n- Use context managers for cleanup\n- Use try/except blocks for expected errors\n- Use raise from for exception chaining\n- Use logging for error tracking\n- Maintain error handling at the appropriate level\n- Consider implementing more specific exception types\n- Validate input data using Pydantic models\n- Use type assertions when necessary for type safety\n\nThese patterns will inform error handling implementation throughout the codebase.\n\nError handling must be comprehensive and follow established patterns.\n\n### Security\n- Never hardcode sensitive information\n- Use environment variables for secrets\n- Use secrets module for random values\n- Use hashlib for hashing\n- Use ssl for secure connections\n- Use hmac for message authentication\n- Use cryptography for encryption\n- Implement proper CORS configuration\n- Validate all input data\n- Use secure database connection strings\n\nThese security practices will inform all code generation and review activities.\n\nSecurity practices must be followed without exception for all sensitive operations.\n\n## 4. Refactoring Guidelines\n\n### Single Responsibility Principle\n- Classes should have a single, clear purpose\n- Remove functionality that doesn't align with the class's core responsibility\n- Rename classes to better reflect their focused responsibility\n\nThis principle will inform class design and refactoring decisions throughout the project.\n\nClasses must have a single, clear responsibility and be appropriately named.\n\n### Resource Management\n- Handle directory creation and management at a higher level\n- Data processing classes should not be responsible for ensuring directory existence\n- This separation of concerns makes the code more maintainable and testable\n\nThis pattern will inform resource management and separation of concerns.\n\nResource management must be handled at appropriate levels with clear separation of concerns.\n\n### File Processing\n- Delegate parsing responsibility to dedicated parser classes\n- Keep file movement operations simple and focused\n- Consider moving directory structure management to a configuration/setup module\n\nThis pattern will inform file processing architecture and responsibility separation.\n\nFile processing must follow established patterns with clear responsibility separation.\n\n### Future Considerations\n- Consider implementing dedicated services for specific functionalities\n- Move configuration and setup logic to appropriate modules\n- Enhance error handling with specific exception types and logging\n- Refactor functions with \"and\" in their name into separate functions\n  - Example: "
      },
      {
        "type": "code_reference",
        "text": "\n\nThese considerations will inform future refactoring and improvement decisions.\n\nFuture improvements must maintain code quality and follow established patterns.\n\n## 5. Type Hints and Annotations\n\n### Function Type Hints\n"
      },
      {
        "type": "code_reference",
        "text": "python\nfrom typing import Optional, List, Dict, Any\nfrom datetime import datetime\n\ndef process_stock_data(\n    symbol: str,\n    start_date: datetime,\n    end_date: Optional[datetime] = None\n) -> List[Dict[str, Any]]:\n    \"\"\"Process stock data for a given symbol and date range.\"\"\"\n    pass\n\nasync def fetch_stock_data(\n    symbol: str,\n    session: AsyncSession\n) -> Optional[StockData]:\n    \"\"\"Fetch stock data from database.\"\"\"\n    pass\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThese patterns will inform type hint usage throughout the codebase.\n\nAll functions must include proper type hints for parameters and return values.\n\n### Class Type Hints\n"
      },
      {
        "type": "code_reference",
        "text": "python\nfrom dataclasses import dataclass\nfrom typing import Optional\n\n@dataclass\nclass StockData:\n    symbol: str\n    date: datetime\n    price: int\n    volume: Optional[int] = None\n\nclass StockDataProcessor:\n    def __init__(self, config: Dict[str, Any]) -> None:\n        self.config = config\n\n    async def process(self, data: List[StockData]) -> bool:\n        \"\"\"Process a list of stock data.\"\"\"\n        pass\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThese patterns will inform class type hint usage and dataclass implementation.\n\nAll classes must include proper type hints and use dataclasses where appropriate.\n\n## 6. Async/Await Patterns\n\n### Async Function Structure\n"
      },
      {
        "type": "code_reference",
        "text": "python\nimport asyncio\nimport aiohttp\nfrom typing import List, Dict, Any\n\nasync def fetch_multiple_stocks(\n    symbols: List[str],\n    session: aiohttp.ClientSession\n) -> Dict[str, Any]:\n    \"\"\"Fetch data for multiple stock symbols concurrently.\"\"\"\n    tasks = [\n        fetch_single_stock(symbol, session)\n        for symbol in symbols\n    ]\n    results = await asyncio.gather(*tasks, return_exceptions=True)\n\n    return {\n        symbol: result\n        for symbol, result in zip(symbols, results)\n        if not isinstance(result, Exception)\n    }\n\nasync def fetch_single_stock(\n    symbol: str,\n    session: aiohttp.ClientSession\n) -> Dict[str, Any]:\n    \"\"\"Fetch data for a single stock symbol.\"\"\"\n    try:\n        async with session.get(f\"/api/stocks/{symbol}\") as response:\n            if response.status == 200:\n                return await response.json()\n            else:\n                raise ValueError(f\"Failed to fetch {symbol}\")\n    except Exception as e:\n        logger.error(f\"Error fetching {symbol}: {e}\")\n        raise\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThese patterns will inform async/await implementation throughout the codebase.\n\nAsync functions must include proper error handling and follow established patterns.\n\n### Database Operations\n"
      },
      {
        "type": "code_reference",
        "text": "python\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom typing import Optional\n\nasync def get_stock_data(\n    symbol: str,\n    session: AsyncSession\n) -> Optional[StockData]:\n    \"\"\"Get stock data from database.\"\"\"\n    try:\n        result = await session.execute(\n            select(StockData).where(StockData.symbol == symbol)\n        )\n        return result.scalar_one_or_none()\n    except Exception as e:\n        logger.error(f\"Database error for {symbol}: {e}\")\n        raise\n\nasync def save_stock_data(\n    data: StockData,\n    session: AsyncSession\n) -> bool:\n    \"\"\"Save stock data to database.\"\"\"\n    try:\n        session.add(data)\n        await session.commit()\n        return True\n    except Exception as e:\n        await session.rollback()\n        logger.error(f\"Failed to save stock data: {e}\")\n        return False\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThese patterns will inform database operation implementation throughout the project.\n\nDatabase operations must include proper error handling, transaction management, and logging.\n\n## 7. Testing Patterns\n\n### Unit Test Structure\n"
      },
      {
        "type": "code_reference",
        "text": "python\nimport pytest\nfrom unittest.mock import AsyncMock, patch\nfrom typing import List\n\nclass TestStockDataProcessor:\n    \"\"\"Test cases for StockDataProcessor.\"\"\"\n\n    @pytest.fixture\n    def processor(self) -> StockDataProcessor:\n        \"\"\"Create processor instance for testing.\"\"\"\n        config = {\"test\": True, \"timeout\": 30}\n        return StockDataProcessor(config)\n\n    @pytest.fixture\n    def sample_data(self) -> List[StockData]:\n        \"\"\"Create sample stock data for testing.\"\"\"\n        return [\n            StockData(symbol=\"AAPL\", date=datetime.now(), price=15000),\n            StockData(symbol=\"GOOGL\", date=datetime.now(), price=25000)\n        ]\n\n    @pytest.mark.asyncio\n    async def test_process_data_success(\n        self,\n        processor: StockDataProcessor,\n        sample_data: List[StockData]\n    ) -> None:\n        \"\"\"Test successful data processing.\"\"\"\n        with patch.object(processor, '_validate_data') as mock_validate:\n            mock_validate.return_value = True\n\n            result = await processor.process_data(sample_data)\n\n            assert result is True\n            mock_validate.assert_called_once_with(sample_data)\n\n    @pytest.mark.asyncio\n    async def test_process_data_validation_failure(\n        self,\n        processor: StockDataProcessor,\n        sample_data: List[StockData]\n    ) -> None:\n        \"\"\"Test data processing with validation failure.\"\"\"\n        with patch.object(processor, '_validate_data') as mock_validate:\n            mock_validate.return_value = False\n\n            result = await processor.process_data(sample_data)\n\n            assert result is False\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThese patterns will inform unit test structure and implementation throughout the project.\n\nUnit tests must include proper fixtures, async testing, and comprehensive error case coverage.\n\n## 8. Documentation Patterns\n\n### Module Docstrings\n"
      },
      {
        "type": "code_reference",
        "text": "python\n\"\"\"\nStock Data Processing Module\n\nThis module provides functionality for retrieving, processing, and storing\nstock market data from various sources. It includes data validation,\ntransformation, and database operations.\n\nKey Components:\n- StockDataRetriever: Handles data retrieval from external APIs\n- StockDataProcessor: Processes and validates stock data\n- StockDataLoader: Manages database operations for stock data\n\nDependencies:\n- aiohttp: For async HTTP requests\n- sqlalchemy: For database operations\n- pydantic: For data validation\n\nExample Usage:\n    processor = StockDataProcessor(config)\n    data = await processor.process_symbol(\"AAPL\")\n\"\"\"\n\nimport asyncio\nimport logging\nfrom typing import List, Dict, Any\n"
      },
      {
        "type": "code_reference",
        "text": "\n\nThese patterns will inform module documentation throughout the project.\n\nAll modules must include comprehensive docstrings with purpose, components, and usage examples.\n\n### Function Docstrings\n"
      },
      {
        "type": "code_reference",
        "text": "python\nasync def process_stock_data(\n    symbol: str,\n    start_date: datetime,\n    end_date: Optional[datetime] = None\n) -> List[Dict[str, Any]]:\n    \"\"\"\n    Process stock data for a given symbol and date range.\n\n    Args:\n        symbol: Stock symbol (e.g., 'AAPL', 'GOOGL')\n        start_date: Start date for data retrieval\n        end_date: End date for data retrieval (defaults to current date)\n\n    Returns:\n        List of processed stock data dictionaries\n\n    Raises:\n        ValueError: If symbol is invalid or date range is invalid\n        ConnectionError: If unable to connect to data source\n\n    Example:\n        data = await process_stock_data(\"AAPL\", datetime(2024, 1, 1))\n    \"\"\"\n    pass\n"
      }
    ],
    "raw_content": "# Python Style Guide\n\n> This guide provides comprehensive Python coding standards and best practices. Use these patterns to ensure consistent, readable, and maintainable Python code.\n\n## AI Metadata\n\n**Template Version:** 2.1\n**AI Processing Level:** High\n**Required Context:** Python language features, project architecture, existing codebase\n**Validation Required:** Yes\n**Code Generation:** Supported\n\n**Dependencies:**\n- `../Core%20Principles.md` - Decision-making frameworks\n- `../project_context/Common%20Patterns.md` - Project patterns\n- `../project_context/Architecture%20Overview.md` - System architecture\n- `FastAPI%20Development%20Guide.md` - API development patterns\n- `Python%20Testing%20Guide.md` - Testing patterns\n\n**Validation Rules:**\n- All code must follow PEP 8 style guidelines\n- Type hints must be used for all function parameters and return values\n- Docstrings must be included for all modules, classes, and functions\n- Import organization must follow established patterns\n- Error handling must follow project conventions\n\n## Overview\n\n**Document Purpose:** Python coding standards and best practices for the CreamPie project\n**Scope:** All Python code, including backend APIs, data processing, and utilities\n**Target Users:** AI assistants and developers writing Python code\n**Last Updated:** Current\n\n**AI Context:** This guide provides the foundational Python coding standards that must be followed for all Python code in the project. It ensures consistency, readability, and maintainability across the codebase.\n\n## 1. Code Style and Best Practices\n\n### General Guidelines\n- Follow PEP 8 style guide\n- Use type hints for all function parameters and return values\n  - Use `|` for union types in Python 3.10+\n  - Use built-in types (`dict`, `list`, `set`, etc.) instead of `typing.Dict`, `typing.List`, etc.\n  - Only import from `typing` for types that don't have built-in equivalents\n- Use docstrings for all modules, classes, and functions\n- Use meaningful variable and function names\n- Keep functions small and focused\n- Do not use magic numbers that are not 1, 2, -1 or 0\n\nThese guidelines will inform all Python code generation and review activities.\n\nAll generated code must follow these guidelines without exception.\n\n### Import Organization\n- Group imports in the following order:\n  1. Standard library imports\n  2. Third-party imports\n  3. Local application imports\n- Separate imports with a blank line between groups\n- Remove unused imports to keep the codebase clean\n- Use direct access to settings when appropriate instead of creating local variables\n- Place `__all__` at the top of a module after imports\n\nThis organization will inform import structure for all Python modules.\n\nImport organization must follow this exact order and grouping.\n\n### Data Structures and Operations\n- Use dataclasses for data containers\n- Use enums for constants\n- Use list comprehensions for simple transformations\n- Use generator expressions for large datasets\n- Use sets for membership testing\n- Use dict.get() for safe access\n- Use collections.deque for queues\n\nThese patterns will inform data structure selection and usage throughout the codebase.\n\nData structure usage must be appropriate for the specific use case and performance requirements.\n\n### File and Path Handling\n- Use os.path for file paths\n  - os.path is preferred over pathlib because it works as strings instead of needing to be coerced\n- Use the standard `datetime` library for date/time operations\n  - Use `datetime.now(datetime.UTC)` instead of `datetime.utcnow()`, which is deprecated\n  - This provides better timezone awareness and is the preferred method in modern Python\n\nThese patterns will inform file and path handling implementation throughout the project.\n\nFile and path handling must use the specified libraries and methods.\n\n### AI Script Development Patterns\n- **Report Generation**: Always generate both human-readable (Markdown) and machine-readable (JSON) reports\n  - Use consistent AI metadata and cross-references in all generated reports\n  - Include timestamps, success/failure metrics, and actionable recommendations\n- **Error Handling**: Use comprehensive try/except blocks with detailed error messages\n  - Collect errors in lists for batch reporting\n  - Provide both console output and structured file output\n- **Link Validation**: Implement intelligent false-positive detection for URL-encoded and relative links\n  - Check for directory references, script files, and configuration files\n  - Handle URL-encoded links with proper decoding\n- **Function Complexity**: Break complex functions into smaller, focused helper methods\n  - Prefer single return points for complex validation functions\n  - Use descriptive method names that clearly indicate their purpose\n- **Unused Variables**: Use underscore prefix for unused loop variables (e.g., `_dirs`, `_link_text`)\n  - This satisfies linting requirements while maintaining code clarity\n- **String Formatting**: Use f-strings for dynamic content, break long strings for readability\n  - Extract complex expressions into variables to avoid line length violations\n  - Use multi-line string concatenation for complex report generation\n- **Performance Considerations**: Optimize for readability over performance in non-critical paths\n  - AI scripts are typically run infrequently, so maintainability is more important than speed\n  - Use clear, explicit logic even if it means multiple checks\n\nThese patterns will inform AI script development and maintenance throughout the project.\n\nAI scripts must follow these patterns for consistency, maintainability, and AI tool consumption.\n\n### Resource Management\n- Split context manager creation into separate statements when the constructor has many parameters or is difficult to read\n- Simple context managers with few or no parameters can remain inline\n- Factory functions (like `AsyncSessionLocal()`) are simple enough to use inline\n\n```python\n# Good - complex constructor with many parameters\nsession = aiohttp.ClientSession(\n    timeout=timeout,\n    headers=headers,\n    skip_auto_headers=['Accept-Encoding']\n)\nasync with session:\n    # use session\n\n# Avoid - complex constructor inline makes it hard to read\nasync with aiohttp.ClientSession(\n    timeout=timeout,\n    headers=headers,\n    skip_auto_headers=['Accept-Encoding']\n) as session:\n    # use session\n\n# Good - simple constructor can remain inline\nasync with ClientSession() as session:\n    # use session\n\n# Good - factory functions can remain inline\nasync with AsyncSessionLocal() as session:\n    # use session\n\n# Good - simple context managers with few parameters\nwith open('file.txt', 'r') as f:\n    # use file\n```\n\nThese patterns will inform context manager usage and resource management throughout the codebase.\n\nContext manager usage must follow these readability guidelines.\n\n### Configuration Management\n- Load configuration once at module level to avoid redundant calls\n- Use module-level variables for configuration that doesn't change during runtime\n- Avoid calling configuration functions multiple times in the same module\n\n```python\n# Good - load once at module level\nconfig = get_stock_data_config()\n\ndef some_function():\n    retriever = StockDataRetriever(config=config)  # Use module-level config\n\n# Avoid - loading config multiple times\ndef some_function():\n    config = get_stock_data_config()  # Redundant call\n    retriever = StockDataRetriever(config=config)\n```\n\nThis pattern will inform configuration loading and usage throughout the project.\n\nConfiguration must be loaded once at module level and reused, not loaded multiple times.\n\n### Constants and Magic Numbers\n- Define constants at module level for configuration values\n- Use descriptive names for time intervals and other magic numbers\n- Group related constants together\n\n```python\n# Good - named constants\nRETRIEVAL_INTERVAL_SECONDS = 5 * 60\nPROCESSING_INTERVAL_SECONDS = 10 * 60\n\n# Avoid - magic numbers in code\nawait asyncio.sleep(5 * 60)  # What does 300 seconds mean?\n```\n\nThis pattern will inform constant definition and usage throughout the codebase.\n\nMagic numbers must be replaced with named constants unless they are 1, 2, -1, or 0.\n\n## 2. Project Structure and Organization\n\n### Directory Structure\n```\ncream_api/\n├── __init__.py\n├── migrations/\n│   ├── __init__.py      # Required for proper package structure\n│   ├── env.py           # Import all models here\n│   └── versions/        # Migration files\n├── models/\n│   └── __init__.py\n└── ...\n```\n\nThis structure will inform package organization and module placement throughout the project.\n\nDirectory structure must follow this organization for consistency and maintainability.\n\n### Package Organization\n- Keep related functionality in dedicated modules\n- Use `__init__.py` files to mark directories as Python packages\n- Separate configuration, database, and application logic into different modules\n- Never have circular imports\n- Use absolute imports for clarity\n\nThis organization will inform module structure and import patterns throughout the project.\n\nPackage organization must avoid circular imports and maintain clear separation of concerns.\n\n## 3. Error Handling and Security\n\n### Error Handling\n- Use custom exceptions for domain-specific errors\n- Use context managers for cleanup\n- Use try/except blocks for expected errors\n- Use raise from for exception chaining\n- Use logging for error tracking\n- Maintain error handling at the appropriate level\n- Consider implementing more specific exception types\n- Validate input data using Pydantic models\n- Use type assertions when necessary for type safety\n\nThese patterns will inform error handling implementation throughout the codebase.\n\nError handling must be comprehensive and follow established patterns.\n\n### Security\n- Never hardcode sensitive information\n- Use environment variables for secrets\n- Use secrets module for random values\n- Use hashlib for hashing\n- Use ssl for secure connections\n- Use hmac for message authentication\n- Use cryptography for encryption\n- Implement proper CORS configuration\n- Validate all input data\n- Use secure database connection strings\n\nThese security practices will inform all code generation and review activities.\n\nSecurity practices must be followed without exception for all sensitive operations.\n\n## 4. Refactoring Guidelines\n\n### Single Responsibility Principle\n- Classes should have a single, clear purpose\n- Remove functionality that doesn't align with the class's core responsibility\n- Rename classes to better reflect their focused responsibility\n\nThis principle will inform class design and refactoring decisions throughout the project.\n\nClasses must have a single, clear responsibility and be appropriately named.\n\n### Resource Management\n- Handle directory creation and management at a higher level\n- Data processing classes should not be responsible for ensuring directory existence\n- This separation of concerns makes the code more maintainable and testable\n\nThis pattern will inform resource management and separation of concerns.\n\nResource management must be handled at appropriate levels with clear separation of concerns.\n\n### File Processing\n- Delegate parsing responsibility to dedicated parser classes\n- Keep file movement operations simple and focused\n- Consider moving directory structure management to a configuration/setup module\n\nThis pattern will inform file processing architecture and responsibility separation.\n\nFile processing must follow established patterns with clear responsibility separation.\n\n### Future Considerations\n- Consider implementing dedicated services for specific functionalities\n- Move configuration and setup logic to appropriate modules\n- Enhance error handling with specific exception types and logging\n- Refactor functions with \"and\" in their name into separate functions\n  - Example: `process_and_validate_data()` should be split into `process_data()` and `validate_data()`\n\nThese considerations will inform future refactoring and improvement decisions.\n\nFuture improvements must maintain code quality and follow established patterns.\n\n## 5. Type Hints and Annotations\n\n### Function Type Hints\n```python\nfrom typing import Optional, List, Dict, Any\nfrom datetime import datetime\n\ndef process_stock_data(\n    symbol: str,\n    start_date: datetime,\n    end_date: Optional[datetime] = None\n) -> List[Dict[str, Any]]:\n    \"\"\"Process stock data for a given symbol and date range.\"\"\"\n    pass\n\nasync def fetch_stock_data(\n    symbol: str,\n    session: AsyncSession\n) -> Optional[StockData]:\n    \"\"\"Fetch stock data from database.\"\"\"\n    pass\n```\n\nThese patterns will inform type hint usage throughout the codebase.\n\nAll functions must include proper type hints for parameters and return values.\n\n### Class Type Hints\n```python\nfrom dataclasses import dataclass\nfrom typing import Optional\n\n@dataclass\nclass StockData:\n    symbol: str\n    date: datetime\n    price: int\n    volume: Optional[int] = None\n\nclass StockDataProcessor:\n    def __init__(self, config: Dict[str, Any]) -> None:\n        self.config = config\n\n    async def process(self, data: List[StockData]) -> bool:\n        \"\"\"Process a list of stock data.\"\"\"\n        pass\n```\n\nThese patterns will inform class type hint usage and dataclass implementation.\n\nAll classes must include proper type hints and use dataclasses where appropriate.\n\n## 6. Async/Await Patterns\n\n### Async Function Structure\n```python\nimport asyncio\nimport aiohttp\nfrom typing import List, Dict, Any\n\nasync def fetch_multiple_stocks(\n    symbols: List[str],\n    session: aiohttp.ClientSession\n) -> Dict[str, Any]:\n    \"\"\"Fetch data for multiple stock symbols concurrently.\"\"\"\n    tasks = [\n        fetch_single_stock(symbol, session)\n        for symbol in symbols\n    ]\n    results = await asyncio.gather(*tasks, return_exceptions=True)\n\n    return {\n        symbol: result\n        for symbol, result in zip(symbols, results)\n        if not isinstance(result, Exception)\n    }\n\nasync def fetch_single_stock(\n    symbol: str,\n    session: aiohttp.ClientSession\n) -> Dict[str, Any]:\n    \"\"\"Fetch data for a single stock symbol.\"\"\"\n    try:\n        async with session.get(f\"/api/stocks/{symbol}\") as response:\n            if response.status == 200:\n                return await response.json()\n            else:\n                raise ValueError(f\"Failed to fetch {symbol}\")\n    except Exception as e:\n        logger.error(f\"Error fetching {symbol}: {e}\")\n        raise\n```\n\nThese patterns will inform async/await implementation throughout the codebase.\n\nAsync functions must include proper error handling and follow established patterns.\n\n### Database Operations\n```python\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom typing import Optional\n\nasync def get_stock_data(\n    symbol: str,\n    session: AsyncSession\n) -> Optional[StockData]:\n    \"\"\"Get stock data from database.\"\"\"\n    try:\n        result = await session.execute(\n            select(StockData).where(StockData.symbol == symbol)\n        )\n        return result.scalar_one_or_none()\n    except Exception as e:\n        logger.error(f\"Database error for {symbol}: {e}\")\n        raise\n\nasync def save_stock_data(\n    data: StockData,\n    session: AsyncSession\n) -> bool:\n    \"\"\"Save stock data to database.\"\"\"\n    try:\n        session.add(data)\n        await session.commit()\n        return True\n    except Exception as e:\n        await session.rollback()\n        logger.error(f\"Failed to save stock data: {e}\")\n        return False\n```\n\nThese patterns will inform database operation implementation throughout the project.\n\nDatabase operations must include proper error handling, transaction management, and logging.\n\n## 7. Testing Patterns\n\n### Unit Test Structure\n```python\nimport pytest\nfrom unittest.mock import AsyncMock, patch\nfrom typing import List\n\nclass TestStockDataProcessor:\n    \"\"\"Test cases for StockDataProcessor.\"\"\"\n\n    @pytest.fixture\n    def processor(self) -> StockDataProcessor:\n        \"\"\"Create processor instance for testing.\"\"\"\n        config = {\"test\": True, \"timeout\": 30}\n        return StockDataProcessor(config)\n\n    @pytest.fixture\n    def sample_data(self) -> List[StockData]:\n        \"\"\"Create sample stock data for testing.\"\"\"\n        return [\n            StockData(symbol=\"AAPL\", date=datetime.now(), price=15000),\n            StockData(symbol=\"GOOGL\", date=datetime.now(), price=25000)\n        ]\n\n    @pytest.mark.asyncio\n    async def test_process_data_success(\n        self,\n        processor: StockDataProcessor,\n        sample_data: List[StockData]\n    ) -> None:\n        \"\"\"Test successful data processing.\"\"\"\n        with patch.object(processor, '_validate_data') as mock_validate:\n            mock_validate.return_value = True\n\n            result = await processor.process_data(sample_data)\n\n            assert result is True\n            mock_validate.assert_called_once_with(sample_data)\n\n    @pytest.mark.asyncio\n    async def test_process_data_validation_failure(\n        self,\n        processor: StockDataProcessor,\n        sample_data: List[StockData]\n    ) -> None:\n        \"\"\"Test data processing with validation failure.\"\"\"\n        with patch.object(processor, '_validate_data') as mock_validate:\n            mock_validate.return_value = False\n\n            result = await processor.process_data(sample_data)\n\n            assert result is False\n```\n\nThese patterns will inform unit test structure and implementation throughout the project.\n\nUnit tests must include proper fixtures, async testing, and comprehensive error case coverage.\n\n## 8. Documentation Patterns\n\n### Module Docstrings\n```python\n\"\"\"\nStock Data Processing Module\n\nThis module provides functionality for retrieving, processing, and storing\nstock market data from various sources. It includes data validation,\ntransformation, and database operations.\n\nKey Components:\n- StockDataRetriever: Handles data retrieval from external APIs\n- StockDataProcessor: Processes and validates stock data\n- StockDataLoader: Manages database operations for stock data\n\nDependencies:\n- aiohttp: For async HTTP requests\n- sqlalchemy: For database operations\n- pydantic: For data validation\n\nExample Usage:\n    processor = StockDataProcessor(config)\n    data = await processor.process_symbol(\"AAPL\")\n\"\"\"\n\nimport asyncio\nimport logging\nfrom typing import List, Dict, Any\n```\n\nThese patterns will inform module documentation throughout the project.\n\nAll modules must include comprehensive docstrings with purpose, components, and usage examples.\n\n### Function Docstrings\n```python\nasync def process_stock_data(\n    symbol: str,\n    start_date: datetime,\n    end_date: Optional[datetime] = None\n) -> List[Dict[str, Any]]:\n    \"\"\"\n    Process stock data for a given symbol and date range.\n\n    Args:\n        symbol: Stock symbol (e.g., 'AAPL', 'GOOGL')\n        start_date: Start date for data retrieval\n        end_date: End date for data retrieval (defaults to current date)\n\n    Returns:\n        List of processed stock data dictionaries\n\n    Raises:\n        ValueError: If symbol is invalid or date range is invalid\n        ConnectionError: If unable to connect to data source\n\n    Example:\n        data = await process_stock_data(\"AAPL\", datetime(2024, 1, 1))\n    \"\"\"\n    pass\n```\n\nThese patterns will inform function documentation throughout the project.\n\nAll functions must include comprehensive docstrings with parameters, return values, exceptions, and examples.\n\n## Implementation Guidelines\n\n### For AI Assistants\n1. **Follow this guide** for all Python code generation\n2. **Use type hints** for all functions and classes\n3. **Include docstrings** for all modules, classes, and functions\n4. **Follow PEP 8** for code formatting and style\n5. **Apply error handling** patterns consistently\n6. **Use async/await** for I/O operations\n7. **Validate inputs** using Pydantic models\n8. **Write tests** for all new functionality\n\n### For Human Developers\n1. **Reference this guide** when writing Python code\n2. **Use type hints** to improve code clarity and IDE support\n3. **Write comprehensive docstrings** for maintainability\n4. **Follow established patterns** for consistency\n5. **Test your code** thoroughly\n6. **Review code** against these standards\n7. **Suggest improvements** when better patterns are found\n\n## Quality Assurance\n\n### Code Quality Standards\n- All code must follow PEP 8 style guidelines\n- Type hints must be used consistently\n- Docstrings must be comprehensive and accurate\n- Error handling must be appropriate and comprehensive\n- Security practices must be followed without exception\n\n### Testing Requirements\n- All new functionality must include unit tests\n- Tests must cover both success and failure cases\n- Async functions must be tested with proper async testing\n- Mocking must be used appropriately for external dependencies\n\n### Documentation Standards\n- All modules must include comprehensive docstrings\n- Function docstrings must include parameters, return values, and examples\n- Complex logic must be documented with comments\n- Architecture decisions must be documented\n\n### Performance Considerations\n- Use async/await for I/O operations\n- Use appropriate data structures for performance\n- Avoid unnecessary object creation\n- Profile code when performance issues arise\n\n---\n\n**AI Quality Checklist**: Before generating Python code, ensure:\n- [x] Code follows PEP 8 style guidelines\n- [x] Type hints are used for all functions and classes\n- [x] Docstrings are comprehensive and accurate\n- [x] Error handling follows established patterns\n- [x] Security practices are implemented\n- [x] Async/await is used for I/O operations\n- [x] Input validation is implemented\n- [x] Tests are included for new functionality\n"
  },
  "cross_references": [],
  "code_generation_hints": [
    {
      "context": "general",
      "hint": "These guidelines will inform all Python code generation and review activities.",
      "validation": ""
    },
    {
      "context": "import organization",
      "hint": "This organization will inform import structure for all Python modules.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "These patterns will inform data structure selection and usage throughout the codebase.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "These patterns will inform file and path handling implementation throughout the project.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "These patterns will inform AI script development and maintenance throughout the project.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "These patterns will inform context manager usage and resource management throughout the codebase.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "This pattern will inform configuration loading and usage throughout the project.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "This pattern will inform constant definition and usage throughout the codebase.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "This structure will inform package organization and module placement throughout the project.",
      "validation": ""
    },
    {
      "context": "import organization",
      "hint": "This organization will inform module structure and import patterns throughout the project.",
      "validation": ""
    },
    {
      "context": "error handling",
      "hint": "These patterns will inform error handling implementation throughout the codebase.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "These security practices will inform all code generation and review activities.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "This principle will inform class design and refactoring decisions throughout the project.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "This pattern will inform resource management and separation of concerns.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "This pattern will inform file processing architecture and responsibility separation.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "These considerations will inform future refactoring and improvement decisions.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "These patterns will inform type hint usage throughout the codebase.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "These patterns will inform class type hint usage and dataclass implementation.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "These patterns will inform async/await implementation throughout the codebase.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "These patterns will inform database operation implementation throughout the project.",
      "validation": ""
    },
    {
      "context": "testing",
      "hint": "These patterns will inform unit test structure and implementation throughout the project.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "These patterns will inform module documentation throughout the project.",
      "validation": ""
    },
    {
      "context": "general",
      "hint": "These patterns will inform function documentation throughout the project.",
      "validation": ""
    }
  ],
  "validation_rules": [
    "Function docstrings must include parameters, return values, and examples",
    "Package organization must avoid circular imports and maintain clear separation of concerns",
    "All modules must include comprehensive docstrings with purpose, components, and usage examples",
    "Async functions must include proper error handling and follow established patterns",
    "Resource management must be handled at appropriate levels with clear separation of concerns",
    "Tests must cover both success and failure cases",
    "Docstrings must be comprehensive and accurate",
    "Directory structure must follow this organization for consistency and maintainability",
    "Async functions must be tested with proper async testing",
    "All code must follow PEP 8 style guidelines",
    "Docstrings must be included for all modules, classes, and functions",
    "Classes should have a single, clear purpose",
    "Future improvements must maintain code quality and follow established patterns",
    "Magic numbers must be replaced with named constants unless they are 1, 2, -1, or 0",
    "Architecture decisions must be documented",
    "Error handling must follow project conventions",
    "Configuration must be loaded once at module level and reused, not loaded multiple times",
    "Context manager usage must follow these readability guidelines",
    "Error handling must be comprehensive and follow established patterns",
    "Complex logic must be documented with comments",
    "All functions must include comprehensive docstrings with parameters, return values, exceptions, and examples",
    "Data processing classes should not be responsible for ensuring directory existence",
    "Data structure usage must be appropriate for the specific use case and performance requirements",
    "File processing must follow established patterns with clear responsibility separation",
    "Import organization must follow established patterns",
    "Security practices must be followed without exception for all sensitive operations",
    "Mocking must be used appropriately for external dependencies",
    "Type hints must be used for all function parameters and return values",
    "All modules must include comprehensive docstrings",
    "All classes must include proper type hints and use dataclasses where appropriate",
    "Import organization must follow this exact order and grouping",
    "Security practices must be followed without exception",
    "Database operations must include proper error handling, transaction management, and logging",
    "Error handling must be appropriate and comprehensive",
    "File and path handling must use the specified libraries and methods",
    "All generated code must follow these guidelines without exception",
    "Unit tests must include proper fixtures, async testing, and comprehensive error case coverage",
    "Classes must have a single, clear responsibility and be appropriately named",
    "Type hints must be used consistently",
    "All new functionality must include unit tests",
    "AI scripts must follow these patterns for consistency, maintainability, and AI tool consumption",
    "Refactor functions with \"and\" in their name into separate functions\n  - Example: `process_and_validate_data()` should be split into `process_data()` and `validate_data()`",
    "All functions must include proper type hints for parameters and return values"
  ],
  "optimization": {
    "version": "1.0",
    "optimized_at": "2025-06-18T19:19:47.743103",
    "improvements": [
      "fixed_file_references",
      "extracted_ai_metadata",
      "structured_cross_references",
      "extracted_code_hints",
      "structured_validation_rules"
    ],
    "literal_strings_cleaned": true,
    "cleaned_at": "2025-06-18T19:30:00.000000"
  }
}