# Cursor Rules for CreamPie Project

## üéØ Primary Reference
**ALWAYS reference the AI rules first: `ai/ai_rules.json`**

This file contains all project rules, patterns, and guidelines in a unified format.

## üö® Critical Immediate Rules (Must Follow)

### Style Guide Compliance (CRITICAL PRIORITY)
**Python style guide violations are CRITICAL priority and block all other work**

**ALWAYS:**
- Check `humans/guides/python_style_guide.md` for requirements
- Include legal notice in module docstring (SPDX format)
- Use proper import organization (stdlib, third-party, local)
- Apply type hints to all functions
- Use proper docstrings with Args/Returns sections
- Use os.path for file operations (not pathlib)
- Use Pydantic v2 patterns

**NEVER:**
- Create code without proper module docstring and legal notice
- Use incorrect import organization
- Skip type hints on functions
- Write incomplete or missing docstrings
- Use pathlib for file operations when os.path is required
- Use deprecated Pydantic v1 patterns

**ENFORCEMENT:** Style guide violations are CRITICAL priority and must be fixed immediately before any other work proceeds.

### Mandatory Debugging Workflow
Before ANY debugging attempt, you MUST:
1. **ALWAYS** check `ai/outputs/lint_results/` for existing tool reports
2. **ALWAYS** check `ai/outputs/test_results/` for existing test failure reports
3. **ALWAYS** check `ai/outputs/` for any other relevant reports
4. **ALWAYS** read the actual error messages from these reports
5. **ONLY THEN** begin debugging based on concrete error information

**NEVER:**
- Start debugging without checking `ai/outputs/` first
- Ask to run tools when error reports already exist
- Make assumptions about error causes
- Guess at missing imports or constants

### Test Assumption Rule (CRITICAL)
**NEVER assume tests pass just because a script executes**

**ALWAYS:**
- Check `ai/outputs/test_results/` for actual test results
- Read test failure reports and error messages
- Verify test outcomes through actual result files

**NEVER:**
- Assume tests pass because a script ran without errors
- Ignore test result files in `ai/outputs/test_results/`
- Make assumptions about test success without checking reports
- Proceed as if tests passed without verification

**ENFORCEMENT:** This rule prevents false assumptions and wasted debugging time.

### Helper Script JSON Output Rule (CRITICAL)
**ALL helper scripts MUST generate JSON output for AI tooling**

**ALWAYS:**
- Generate JSON output in `ai/outputs/` with proper categorization
- Include structured metadata, results, and status information
- Provide both human-readable (terminal) and machine-readable (JSON) outputs
- Follow established JSON schema patterns
- Use `scripts/ai_health_check.py` as reference implementation

**NEVER:**
- Create scripts that only output to terminal
- Ignore the need for machine-readable output
- Skip proper error handling and status reporting
- Use inconsistent output formats

**ENFORCEMENT:** This ensures all scripts are AI-friendly and provide structured data for analysis.

### Priority System (Always Apply)
1. **Critical**: Security vulnerabilities, data integrity issues, breaking changes, **style guide violations**
2. **High**: Style violations, performance issues, maintainability problems
3. **Medium**: Code organization, documentation, minor optimizations
4. **Low**: Personal preferences, cosmetic changes, future-proofing

## üìÅ Essential Documentation Structure
- **AI Config**: `ai/ai_config.json` - Central configuration and settings
- **Search Index**: `ai/search_index.json` - Comprehensive navigation guide
- **AI Rules**: `ai/ai_rules.json` - All AI rules and patterns

## üîß Technology-Specific Guidelines
- **Python**: `ai/guide_docs/language_specific/python_style_guide.json`
- **FastAPI**: `ai/guide_docs/language_specific/fastapi_development_guide.json`
- **React**: `ai/guide_docs/language_specific/react_style_guide.json`
- **Database**: `ai/guide_docs/domain_specific/database_management_guide.json`

## üõ†Ô∏è Tool Usage Guidelines
- Use `read_file` before editing to understand context
- Use `edit_file` for precise changes with clear instructions
- Use `codebase_search` for semantic understanding of patterns
- Use `grep_search` for exact text/regex pattern matching
- Use `run_terminal_cmd` for shell operations with `is_background: true` for long-running tasks

## üéØ Context Awareness
- **File Context**: What file they're working in and its purpose
- **Task Context**: What they're trying to accomplish
- **Project Context**: Overall architecture and constraints
- **User Experience Level**: Beginner, Intermediate, or Advanced

## üìû Communication Patterns
- **Positive Feedback**: "Great approach! This follows our established patterns."
- **Constructive Criticism**: "Consider using [pattern] for better [benefit]."
- **Educational Guidance**: "Here's why we use this pattern: [explanation]."

## üîÑ Maintenance
- Use `scripts/ai_health_check.py` for validation
- Maintain cross-references across all documentation
- Update metadata and version information
- Ensure search index accuracy

---

**Remember**: Always maintain context awareness, follow established patterns, prioritize user success over perfect code, and leverage the comprehensive AI documentation system for optimal guidance.

**For complete rules and detailed patterns, always reference: `ai/ai_rules.json`**
